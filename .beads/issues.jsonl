{"id":"migrate-egghead-04y","title":"Auth Cutover Runbook","description":"Explicit auth cutover strategy. Users must be able to log in seamlessly during and after migration.\n\nKey considerations:\n- OAuth tokens (GitHub, Discord) need re-linking flow\n- Session tokens in flight during cutover\n- OAuth-only users (never set password) need special handling\n- Password reset email campaign timing\n- Support playbook for locked-out users","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:53:25.98898-08:00","updated_at":"2025-12-11T09:53:25.98898-08:00"}
{"id":"migrate-egghead-04y.1","title":"Build OAuth provider re-linking flow (GitHub, Discord)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:26.023733-08:00","updated_at":"2025-12-11T09:53:26.023733-08:00","dependencies":[{"issue_id":"migrate-egghead-04y.1","depends_on_id":"migrate-egghead-04y","type":"parent-child","created_at":"2025-12-11T09:53:26.02412-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-04y.2","title":"Implement session invalidation strategy for cutover","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:26.058007-08:00","updated_at":"2025-12-11T09:53:26.058007-08:00","dependencies":[{"issue_id":"migrate-egghead-04y.2","depends_on_id":"migrate-egghead-04y","type":"parent-child","created_at":"2025-12-11T09:53:26.058363-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-04y.3","title":"Build OAuth-only user detection and password set flow","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:26.091729-08:00","updated_at":"2025-12-11T09:53:26.091729-08:00","dependencies":[{"issue_id":"migrate-egghead-04y.3","depends_on_id":"migrate-egghead-04y","type":"parent-child","created_at":"2025-12-11T09:53:26.092033-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-04y.4","title":"Create password reset email campaign (timing: 48h before cutover)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:26.124375-08:00","updated_at":"2025-12-11T09:53:26.124375-08:00","dependencies":[{"issue_id":"migrate-egghead-04y.4","depends_on_id":"migrate-egghead-04y","type":"parent-child","created_at":"2025-12-11T09:53:26.124718-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-04y.5","title":"Write support playbook for locked-out users","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:26.155584-08:00","updated_at":"2025-12-11T09:53:26.155584-08:00","dependencies":[{"issue_id":"migrate-egghead-04y.5","depends_on_id":"migrate-egghead-04y","type":"parent-child","created_at":"2025-12-11T09:53:26.15594-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-04y.6","title":"Build auth status dashboard (monitor login success rate)","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:53:26.18637-08:00","updated_at":"2025-12-11T09:53:26.18637-08:00","dependencies":[{"issue_id":"migrate-egghead-04y.6","depends_on_id":"migrate-egghead-04y","type":"parent-child","created_at":"2025-12-11T09:53:26.1867-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-04y.7","title":"Test cutover with 100 real users (beta group)","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:53:26.215844-08:00","updated_at":"2025-12-11T09:53:26.215844-08:00","dependencies":[{"issue_id":"migrate-egghead-04y.7","depends_on_id":"migrate-egghead-04y","type":"parent-child","created_at":"2025-12-11T09:53:26.216166-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx","title":"Migration Support Automation System","description":"Build a multi-tenant AI-powered support platform. egghead migration is the first tenant, but architecture supports all Skill Recordings properties (Total TypeScript, Pro Tailwind, etc.) and beyond.\n\n## Multi-Tenant Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    SUPPORT PLATFORM (Multi-Tenant)              â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Tenant Config                                                   â”‚\nâ”‚  â”œâ”€ egghead     { frontInbox, stripeAccount, db, branding }    â”‚\nâ”‚  â”œâ”€ totaltypescript  { ... }                                    â”‚\nâ”‚  â”œâ”€ protailwind      { ... }                                    â”‚\nâ”‚  â””â”€ [future]         { ... }                                    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Shared Infrastructure                                           â”‚\nâ”‚  â”œâ”€ Upstash Redis    (namespaced by tenant)                     â”‚\nâ”‚  â”œâ”€ Upstash Vector   (namespaced by tenant)                     â”‚\nâ”‚  â”œâ”€ Inngest          (tenant in event metadata)                 â”‚\nâ”‚  â””â”€ Front Plugin     (routes by inbox â†’ tenant)                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Tenant-Specific                                                 â”‚\nâ”‚  â”œâ”€ Diagnostic queries (different schemas per app)              â”‚\nâ”‚  â”œâ”€ Auto-resolvers (tenant-specific actions)                    â”‚\nâ”‚  â”œâ”€ Response templates (branding, tone)                         â”‚\nâ”‚  â””â”€ Vector indexes (tenant's docs, tickets, code)               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Tenant Configuration\n\n```typescript\ninterface TenantConfig {\n  id: string                    // 'egghead' | 'totaltypescript' | ...\n  name: string                  // Display name\n  \n  // Front integration\n  front: {\n    inboxIds: string[]          // Which Front inboxes route here\n    webhookSecret: string\n  }\n  \n  // Database (for diagnostics)\n  database: {\n    type: 'planetscale' | 'postgres'\n    connectionString: string\n    schema: TenantSchema        // Tenant-specific query adapters\n  }\n  \n  // Stripe (for billing issues)\n  stripe: {\n    accountId: string\n    secretKey: string\n  }\n  \n  // Branding\n  branding: {\n    name: string\n    supportEmail: string\n    signatureTemplate: string\n  }\n  \n  // Feature flags\n  features: {\n    autoResolve: boolean\n    proactiveMonitor: boolean\n    ragEnabled: boolean\n  }\n}\n```\n\n## Key Design Principles\n\n1. **Namespace everything** - Redis keys, vector namespaces, Inngest events all prefixed with tenant\n2. **Tenant from context** - Front inbox â†’ tenant lookup at webhook entry point\n3. **Shared infra, isolated data** - One Redis/Vector instance, tenant-scoped keys\n4. **Pluggable diagnostics** - Each tenant implements `DiagnosticAdapter` interface\n5. **Tenant-specific resolvers** - Core resolver logic shared, actions tenant-specific\n\n## Success Metrics (per tenant)\n- Auto-resolve rate \u003e 60%\n- Time to first response \u003c 5 min\n- Resolution accuracy \u003e 90% (measured by re-open rate)","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:58:46.697139-08:00","updated_at":"2025-12-11T10:03:15.444102-08:00"}
{"id":"migrate-egghead-1rx.1","title":"Build Front webhook receiver (Inngest function)","description":"Build Front webhook receiver that triggers Inngest functions.\n\nFront webhook events to handle:\n- `inbound` - New message received (classify and route)\n- `outbound` - Reply sent (track resolution)\n- `conversation_assigned` - Assigned to teammate\n- `conversation_unassigned` - Back in queue\n- `tag_added` - Manual categorization\n\nWebhook endpoint: POST /api/webhooks/front\n\nFlow:\n1. Receive webhook from Front\n2. Verify signature (FRONT_WEBHOOK_SECRET)\n3. Extract conversation ID, sender email, message body\n4. Send to Inngest: `support/conversation.received`\n5. Inngest function picks up and starts classification\n\n```typescript\n// Inngest event schema\n{\n  name: 'support/conversation.received',\n  data: {\n    conversationId: string,\n    email: string,\n    subject: string,\n    body: string,\n    inboxId: string,\n    isNewConversation: boolean,\n  }\n}\n```","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:58:46.733845-08:00","updated_at":"2025-12-11T09:58:57.21168-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.1","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T09:58:46.734189-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.10","title":"Build escalation flow with full diagnostic context for humans","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:58:47.02927-08:00","updated_at":"2025-12-11T09:58:47.02927-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.10","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T09:58:47.02963-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.11","title":"Set up Upstash Redis for conversation state + resolution cache","description":"Set up Upstash Redis as the state layer for multi-tenant support infrastructure.\n\n## Multi-Tenant Key Structure\n\nAll keys namespaced by tenant ID:\n\n```typescript\n// Conversation state (TTL: 24h)\n`{tenant}:conv:${conversationId}` â†’ {\n  tenantId: string\n  userId: string\n  classification: Classification\n  diagnostic: UserDiagnostic\n  messages: Message[]\n  resolutionAttempts: ResolutionAttempt[]\n  status: 'open' | 'pending' | 'resolved' | 'escalated'\n}\n\n// User session cache (TTL: 1h)\n`{tenant}:user:${email}` â†’ UserDiagnostic\n\n// Resolution cache - what worked (TTL: 30d)\n`{tenant}:resolution:${issueType}:${specificIssue}` â†’ {\n  successCount: number\n  failureCount: number\n  lastSuccess: Date\n  template: string\n  actions: Action[]\n}\n\n// Pattern counters (TTL: 1h, sliding window)\n`{tenant}:pattern:${issueType}:${hour}` â†’ count\n\n// Rate limiting (per tenant)\n`{tenant}:ratelimit:${email}` â†’ count\n\n// Tenant config cache (TTL: 5min)\n`tenant:config:${tenantId}` â†’ TenantConfig\n```\n\n## Typed Client\n\n```typescript\n// lib/support/redis.ts\nimport { Redis } from '@upstash/redis'\n\nconst redis = new Redis({\n  url: process.env.UPSTASH_REDIS_REST_URL,\n  token: process.env.UPSTASH_REDIS_REST_TOKEN,\n})\n\n// Tenant-scoped helpers\nexport function tenantRedis(tenantId: string) {\n  return {\n    async getConversation(convId: string) {\n      return redis.get\u003cConversation\u003e(`${tenantId}:conv:${convId}`)\n    },\n    async setConversation(convId: string, conv: Conversation) {\n      return redis.set(`${tenantId}:conv:${convId}`, conv, { ex: 86400 })\n    },\n    async getUserCache(email: string) {\n      return redis.get\u003cUserDiagnostic\u003e(`${tenantId}:user:${email}`)\n    },\n    // ... etc\n  }\n}\n```\n\n## Implementation\n\n1. Create Upstash Redis instance\n2. Add UPSTASH_REDIS_REST_URL and UPSTASH_REDIS_REST_TOKEN to env\n3. Create `lib/support/redis.ts` with tenant-scoped client\n4. Create tenant config loader with caching\n5. Add TTL management utilities","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T10:02:06.934623-08:00","updated_at":"2025-12-11T10:03:25.54171-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.11","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T10:02:06.935024-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.12","title":"Set up Upstash Vector for semantic search (docs, tickets, code)","description":"Set up Upstash Vector as the multi-tenant semantic search layer.\n\n## Multi-Tenant Index Strategy\n\nOption A: **Namespaces per tenant** (recommended)\n- Single Upstash Vector index\n- Use namespace parameter: `egghead`, `totaltypescript`, etc.\n- Pros: Simple, cost-effective, easy tenant isolation\n- Cons: Can't have different dimensions per tenant (all use same embedding model)\n\n```typescript\n// Query with namespace\nconst results = await index.query({\n  vector: embedding,\n  topK: 5,\n  namespace: tenantId,  // 'egghead' | 'totaltypescript' | ...\n  filter: { type: 'faq' }\n})\n```\n\n## Index Structure (per namespace)\n\n```typescript\n// Namespace: {tenant}/support-docs\n{\n  id: 'doc-{slug}',\n  vector: float[1536],  // OpenAI text-embedding-3-small\n  metadata: {\n    tenantId: string,\n    type: 'faq' | 'guide' | 'troubleshooting',\n    title: string,\n    content: string,\n    url: string,\n    lastUpdated: string\n  }\n}\n\n// Namespace: {tenant}/past-tickets\n{\n  id: 'ticket-{id}',\n  vector: float[1536],\n  metadata: {\n    tenantId: string,\n    issueType: string,\n    resolution: string,\n    wasSuccessful: boolean,\n    responseTemplate: string,\n    createdAt: string\n  }\n}\n```\n\n## Typed Client\n\n```typescript\n// lib/support/vector.ts\nimport { Index } from '@upstash/vector'\n\nconst index = new Index({\n  url: process.env.UPSTASH_VECTOR_REST_URL,\n  token: process.env.UPSTASH_VECTOR_REST_TOKEN,\n})\n\nexport function tenantVector(tenantId: string) {\n  return {\n    async searchDocs(embedding: number[], topK = 3) {\n      return index.query({\n        vector: embedding,\n        topK,\n        namespace: `${tenantId}/support-docs`,\n        includeMetadata: true,\n      })\n    },\n    async searchTickets(embedding: number[], filter?: object, topK = 3) {\n      return index.query({\n        vector: embedding,\n        topK,\n        namespace: `${tenantId}/past-tickets`,\n        filter,\n        includeMetadata: true,\n      })\n    },\n    async upsertDoc(id: string, embedding: number[], metadata: DocMetadata) {\n      return index.upsert({\n        id,\n        vector: embedding,\n        metadata: { ...metadata, tenantId },\n        namespace: `${tenantId}/support-docs`,\n      })\n    },\n    // ... etc\n  }\n}\n```\n\n## Implementation\n\n1. Create Upstash Vector index (1536 dimensions for OpenAI)\n2. Add UPSTASH_VECTOR_REST_URL and UPSTASH_VECTOR_REST_TOKEN\n3. Create `lib/support/vector.ts` with tenant-namespaced client\n4. Create namespace management utilities\n5. Add tenant isolation tests","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T10:02:12.845266-08:00","updated_at":"2025-12-11T10:03:35.591982-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.12","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T10:02:12.84569-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.13","title":"Build embedding pipeline for support docs + past tickets","description":"Build the embedding pipeline that populates the vector DB.\n\n## Sources to Index\n\n1. **Support Docs** (one-time + on change)\n   - FAQ pages from egghead\n   - Help center articles\n   - Common troubleshooting guides\n   \n2. **Past Tickets** (batch + incremental)\n   - Export from Front (last 6 months)\n   - Extract: issue, resolution, success/failure\n   - Incremental: webhook on ticket close\n   \n3. **Codebase** (optional, on-demand)\n   - Key files: auth, subscriptions, entitlements\n   - Chunk by function/component\n   - Re-index on deploy\n\n## Inngest Functions\n\n```typescript\n// One-time batch indexing\ninngest.createFunction(\n  { id: 'index-support-docs' },\n  { event: 'support/index.docs' },\n  async ({ step }) =\u003e {\n    const docs = await step.run('fetch-docs', fetchAllDocs)\n    for (const doc of docs) {\n      await step.run(`embed-${doc.id}`, () =\u003e embedAndUpsert(doc))\n    }\n  }\n)\n\n// Incremental on ticket close\ninngest.createFunction(\n  { id: 'index-resolved-ticket' },\n  { event: 'support/ticket.resolved' },\n  async ({ event, step }) =\u003e {\n    const embedding = await step.run('embed', () =\u003e \n      embed(event.data.issue + ' ' + event.data.resolution)\n    )\n    await step.run('upsert', () =\u003e \n      vectorUpsert('past-tickets', { ... })\n    )\n  }\n)\n```\n\n## Chunking Strategy\n\n- Docs: Split by section (h2/h3 headers)\n- Tickets: Full ticket as single chunk\n- Code: Function/component boundaries","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T10:02:21.811817-08:00","updated_at":"2025-12-11T10:02:21.811817-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.13","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T10:02:21.812283-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.14","title":"Build RAG retrieval layer (query vector DB before AI response)","description":"Build the RAG retrieval layer that enriches AI responses with relevant context.\n\n## Flow\n\n```\nUser Message\n    â†“\nEmbed Query (OpenAI ada-002)\n    â†“\nParallel Vector Search:\nâ”œâ”€ support-docs (top 3)\nâ”œâ”€ past-tickets (top 3, filter: wasSuccessful=true)\nâ””â”€ codebase (top 2, if technical)\n    â†“\nContext Assembly\n    â†“\nLLM with enriched context\n    â†“\nResponse\n```\n\n## Implementation\n\n```typescript\ninterface RAGContext {\n  relevantDocs: { title: string; content: string; url: string }[]\n  similarTickets: { issue: string; resolution: string; template: string }[]\n  codeContext?: { file: string; snippet: string }[]\n}\n\nasync function retrieveContext(\n  query: string,\n  classification: Classification\n): Promise\u003cRAGContext\u003e {\n  const embedding = await embed(query)\n  \n  const [docs, tickets, code] = await Promise.all([\n    vectorQuery('support-docs', embedding, { topK: 3 }),\n    vectorQuery('past-tickets', embedding, { \n      topK: 3, \n      filter: { wasSuccessful: true, issueType: classification.category }\n    }),\n    classification.isTechnical \n      ? vectorQuery('codebase', embedding, { topK: 2 })\n      : null\n  ])\n  \n  return { relevantDocs: docs, similarTickets: tickets, codeContext: code }\n}\n\n// Use in classifier/resolver\nconst context = await retrieveContext(message, classification)\nconst response = await openai.chat.completions.create({\n  messages: [\n    { role: 'system', content: buildSystemPrompt(context) },\n    { role: 'user', content: message }\n  ]\n})\n```\n\n## System Prompt Template\n\n```\nYou are an egghead.io support agent. Use the following context to help the user:\n\n## Relevant Documentation\n{docs}\n\n## Similar Resolved Tickets\n{tickets}\n\n## User Diagnostic\n{diagnostic}\n\nRespond helpfully and concisely. If you can resolve the issue, do so. If not, explain what you need.\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T10:02:31.388956-08:00","updated_at":"2025-12-11T10:02:31.388956-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.14","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T10:02:31.389331-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.15","title":"Build resolution memory (track what worked, surface for similar issues)","description":"Build the resolution memory system that learns from outcomes.\n\n## Data Model\n\n```typescript\ninterface Resolution {\n  id: string\n  issueType: Category\n  specificIssue: string  // e.g., \"password_reset\", \"missing_entitlement\"\n  \n  // What we did\n  actions: Action[]\n  responseTemplate: string\n  \n  // Outcome tracking\n  attempts: number\n  successes: number\n  failures: number\n  successRate: number\n  \n  // Timing\n  avgResolutionTime: number\n  lastUsed: Date\n  \n  // Feedback\n  userRatings: number[]\n  reopenRate: number\n}\n\ninterface ResolutionAttempt {\n  resolutionId: string\n  conversationId: string\n  timestamp: Date\n  outcome: 'success' | 'failure' | 'pending'\n  userFeedback?: 'positive' | 'negative'\n  reopened: boolean\n}\n```\n\n## Learning Loop\n\n```typescript\n// On ticket close\ninngest.createFunction(\n  { id: 'learn-from-resolution' },\n  { event: 'support/ticket.closed' },\n  async ({ event, step }) =\u003e {\n    const { conversationId, wasReopened, userFeedback } = event.data\n    \n    // Get what we tried\n    const conv = await redis.get(`conv:${conversationId}`)\n    const attempts = conv.resolutionAttempts\n    \n    // Update resolution stats\n    for (const attempt of attempts) {\n      await step.run(`update-${attempt.resolutionId}`, async () =\u003e {\n        const resolution = await getResolution(attempt.resolutionId)\n        \n        if (wasReopened) {\n          resolution.failures++\n          resolution.reopenRate = recalculate(...)\n        } else {\n          resolution.successes++\n        }\n        \n        resolution.successRate = resolution.successes / resolution.attempts\n        await saveResolution(resolution)\n        \n        // Re-embed if success rate changed significantly\n        if (shouldReindex(resolution)) {\n          await inngest.send({ name: 'support/resolution.reindex', data: resolution })\n        }\n      })\n    }\n  }\n)\n```\n\n## Surfacing Best Resolutions\n\n```typescript\nasync function getBestResolution(\n  issueType: Category,\n  specificIssue: string\n): Promise\u003cResolution | null\u003e {\n  // Check cache first\n  const cached = await redis.get(`resolution:${issueType}:${specificIssue}`)\n  if (cached \u0026\u0026 cached.successRate \u003e 0.8) return cached\n  \n  // Query vector DB for similar issues\n  const similar = await vectorQuery('past-tickets', embed(specificIssue), {\n    filter: { issueType, wasSuccessful: true },\n    topK: 5\n  })\n  \n  // Return highest success rate\n  return similar.sort((a, b) =\u003e b.successRate - a.successRate)[0]\n}\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T10:02:41.826336-08:00","updated_at":"2025-12-11T10:02:41.826336-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.15","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T10:02:41.826737-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.16","title":"Build pattern detector (aggregate issues â†’ systemic alerts)","description":"Build pattern detection to catch systemic issues before they become crises.\n\n## Detection Rules\n\n```typescript\ninterface PatternRule {\n  id: string\n  name: string\n  condition: {\n    issueType: Category\n    specificIssue?: string\n    threshold: number      // Count to trigger\n    window: number         // Time window in minutes\n  }\n  action: {\n    alert: 'slack' | 'pagerduty'\n    channel: string\n    severity: 'info' | 'warning' | 'critical'\n    autoAction?: string    // Optional auto-remediation\n  }\n}\n\nconst rules: PatternRule[] = [\n  {\n    id: 'auth-spike',\n    name: 'Authentication Error Spike',\n    condition: { issueType: 'AUTH', threshold: 10, window: 60 },\n    action: { alert: 'slack', channel: '#support-alerts', severity: 'critical' }\n  },\n  {\n    id: 'access-spike',\n    name: 'Access Denied Spike',\n    condition: { issueType: 'ACCESS', threshold: 5, window: 30 },\n    action: { alert: 'slack', channel: '#support-alerts', severity: 'warning' }\n  },\n  {\n    id: 'video-playback',\n    name: 'Video Playback Issues',\n    condition: { issueType: 'CONTENT', specificIssue: 'video_wont_play', threshold: 3, window: 15 },\n    action: { alert: 'slack', channel: '#engineering', severity: 'critical' }\n  }\n]\n```\n\n## Implementation\n\n```typescript\n// Increment counter on every ticket\nasync function trackPattern(classification: Classification) {\n  const hour = new Date().toISOString().slice(0, 13)  // 2024-01-15T14\n  const key = `pattern:${classification.category}:${hour}`\n  \n  const count = await redis.incr(key)\n  await redis.expire(key, 3600)  // 1 hour TTL\n  \n  // Check rules\n  for (const rule of rules) {\n    if (rule.condition.issueType !== classification.category) continue\n    \n    const windowCount = await getWindowCount(\n      classification.category,\n      rule.condition.window\n    )\n    \n    if (windowCount \u003e= rule.condition.threshold) {\n      await triggerAlert(rule, windowCount)\n    }\n  }\n}\n\n// Sliding window count\nasync function getWindowCount(issueType: Category, windowMinutes: number): Promise\u003cnumber\u003e {\n  const now = new Date()\n  const keys = []\n  \n  for (let i = 0; i \u003c Math.ceil(windowMinutes / 60); i++) {\n    const hour = new Date(now.getTime() - i * 60 * 60 * 1000)\n      .toISOString().slice(0, 13)\n    keys.push(`pattern:${issueType}:${hour}`)\n  }\n  \n  const counts = await redis.mget(keys)\n  return counts.reduce((sum, c) =\u003e sum + (parseInt(c) || 0), 0)\n}\n\n// Alert with context\nasync function triggerAlert(rule: PatternRule, count: number) {\n  // Dedupe: don't alert twice in 15 min\n  const alertKey = `alert:${rule.id}`\n  if (await redis.get(alertKey)) return\n  await redis.set(alertKey, '1', { ex: 900 })\n  \n  // Get recent examples\n  const recentTickets = await getRecentTickets(rule.condition.issueType, 5)\n  \n  await slack.send(rule.action.channel, {\n    text: `ğŸš¨ ${rule.name}: ${count} issues in ${rule.condition.window} min`,\n    blocks: [\n      { type: 'section', text: { type: 'mrkdwn', text: `*${rule.name}*\\n${count} issues detected` }},\n      { type: 'section', text: { type: 'mrkdwn', text: `*Recent examples:*\\n${recentTickets.map(t =\u003e `â€¢ ${t.subject}`).join('\\n')}` }}\n    ]\n  })\n}\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T10:02:55.636787-08:00","updated_at":"2025-12-11T10:02:55.636787-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.16","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T10:02:55.637178-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.17","title":"Build tenant configuration system (registry, routing, feature flags)","description":"Build the multi-tenant configuration system that routes requests and manages tenant-specific settings.\n\n## Tenant Registry\n\n```typescript\n// lib/support/tenants/config.ts\ninterface TenantConfig {\n  id: string                    // 'egghead' | 'totaltypescript' | ...\n  name: string                  // Display name\n  \n  // Front integration\n  front: {\n    inboxIds: string[]          // Which Front inboxes route here\n    webhookSecret: string       // Per-tenant webhook verification\n  }\n  \n  // Database (for diagnostics)\n  database: {\n    provider: 'planetscale' | 'neon' | 'supabase'\n    connectionUrl: string       // From env: DATABASE_URL_{TENANT}\n  }\n  \n  // Stripe (for billing issues)\n  stripe: {\n    accountId: string           // Connect account or platform\n    secretKeyEnvVar: string     // STRIPE_SECRET_KEY_{TENANT}\n  }\n  \n  // Branding\n  branding: {\n    displayName: string         // \"egghead.io\" | \"Total TypeScript\"\n    supportEmail: string        // support@egghead.io\n    signatureTemplate: string   // \"Cheers,\\negghead Support\"\n    tone: 'casual' | 'professional' | 'friendly'\n  }\n  \n  // Feature flags\n  features: {\n    autoResolve: boolean        // Can AI auto-resolve without human?\n    proactiveMonitor: boolean   // Run background health checks?\n    ragEnabled: boolean         // Use vector search for context?\n    maxAutoResolvePerHour: number\n  }\n  \n  // Issue categories (can be customized per tenant)\n  categories: Category[]\n}\n\n// Initial tenants\nconst tenants: TenantConfig[] = [\n  {\n    id: 'egghead',\n    name: 'egghead.io',\n    front: {\n      inboxIds: ['inb_xxx'],  // From Front\n      webhookSecret: process.env.FRONT_WEBHOOK_SECRET_EGGHEAD!,\n    },\n    database: {\n      provider: 'planetscale',\n      connectionUrl: process.env.DATABASE_URL_EGGHEAD!,\n    },\n    stripe: {\n      accountId: 'acct_xxx',\n      secretKeyEnvVar: 'STRIPE_SECRET_KEY_EGGHEAD',\n    },\n    branding: {\n      displayName: 'egghead.io',\n      supportEmail: 'support@egghead.io',\n      signatureTemplate: 'Cheers,\\negghead Support',\n      tone: 'casual',\n    },\n    features: {\n      autoResolve: true,\n      proactiveMonitor: true,\n      ragEnabled: true,\n      maxAutoResolvePerHour: 50,\n    },\n    categories: ['AUTH', 'ACCESS', 'PROGRESS', 'CONTENT', 'BILLING', 'TEAM'],\n  },\n  // Add more tenants as needed\n]\n```\n\n## Routing: Inbox â†’ Tenant\n\n```typescript\n// lib/support/tenants/routing.ts\nimport { redis } from '../redis'\n\n// Cache inbox â†’ tenant mapping\nconst inboxToTenant = new Map\u003cstring, string\u003e()\n\nexport async function getTenantFromInbox(inboxId: string): Promise\u003cTenantConfig\u003e {\n  // Check memory cache\n  let tenantId = inboxToTenant.get(inboxId)\n  \n  if (!tenantId) {\n    // Check Redis cache\n    tenantId = await redis.get(`inbox:${inboxId}:tenant`)\n    \n    if (!tenantId) {\n      // Lookup from config\n      const tenant = tenants.find(t =\u003e t.front.inboxIds.includes(inboxId))\n      if (!tenant) throw new Error(`Unknown inbox: ${inboxId}`)\n      tenantId = tenant.id\n      \n      // Cache it\n      await redis.set(`inbox:${inboxId}:tenant`, tenantId, { ex: 3600 })\n    }\n    \n    inboxToTenant.set(inboxId, tenantId)\n  }\n  \n  return getTenant(tenantId)\n}\n\nexport function getTenant(tenantId: string): TenantConfig {\n  const tenant = tenants.find(t =\u003e t.id === tenantId)\n  if (!tenant) throw new Error(`Unknown tenant: ${tenantId}`)\n  return tenant\n}\n```\n\n## Tenant Context in Inngest Events\n\n```typescript\n// All support events include tenant\ninterface SupportEvent {\n  name: `support/${string}`\n  data: {\n    tenantId: string\n    // ... event-specific data\n  }\n}\n\n// Example\nawait inngest.send({\n  name: 'support/conversation.received',\n  data: {\n    tenantId: 'egghead',\n    conversationId: 'cnv_xxx',\n    email: 'user@example.com',\n    // ...\n  }\n})\n```\n\n## Implementation\n\n1. Create `lib/support/tenants/` directory structure\n2. Define TenantConfig type with Zod validation\n3. Create tenant registry with initial egghead config\n4. Build inbox â†’ tenant routing with caching\n5. Create getTenant/getTenantFromInbox helpers\n6. Add tenant validation middleware for Inngest functions\n7. Document env vars needed per tenant","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T10:04:12.476644-08:00","updated_at":"2025-12-11T10:04:12.476644-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.17","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T10:04:12.477063-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.2","title":"Build AI issue classifier (auth/access/progress/content/billing/team)","description":"Build AI issue classifier using structured output.\n\nCategories:\n- AUTH: Login issues, password reset, OAuth, \"can't sign in\"\n- ACCESS: Pro access lost, entitlements, \"can't watch\", paywall\n- PROGRESS: Course progress missing, completion status, certificates\n- CONTENT: Video won't play, lesson missing, 404 errors\n- BILLING: Refund request, double charge, invoice, subscription\n- TEAM: Team access, seats, invites, member management\n- OTHER: Escalate to human\n\nImplementation:\n```typescript\nconst classifyIssue = inngest.createFunction(\n  { id: 'classify-support-issue' },\n  { event: 'support/conversation.received' },\n  async ({ event, step }) =\u003e {\n    const classification = await step.run('classify', async () =\u003e {\n      return openai.chat.completions.create({\n        model: 'gpt-4o',\n        messages: [{\n          role: 'system',\n          content: `Classify this support request into one category:\n            AUTH, ACCESS, PROGRESS, CONTENT, BILLING, TEAM, OTHER\n            \n            Also extract:\n            - urgency (low/medium/high/critical)\n            - sentiment (frustrated/neutral/positive)\n            - specific_issue (e.g., \"password_reset\", \"refund_request\")\n            - can_auto_resolve (boolean)`\n        }, {\n          role: 'user',\n          content: `Subject: ${event.data.subject}\\n\\n${event.data.body}`\n        }],\n        response_format: { type: 'json_schema', ... }\n      })\n    })\n    \n    // Route to appropriate resolver\n    await step.sendEvent('route', {\n      name: `support/issue.${classification.category.toLowerCase()}`,\n      data: { ...event.data, classification }\n    })\n  }\n)\n```","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:58:46.769268-08:00","updated_at":"2025-12-11T09:59:04.571343-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.2","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T09:58:46.769616-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.3","title":"Build diagnostic engine - gather all user context automatically","description":"Build diagnostic engine with pluggable tenant adapters.\n\n## Multi-Tenant Diagnostic Architecture\n\nEach tenant has different database schemas, so diagnostics are pluggable:\n\n```typescript\n// Core interface - all tenants implement this\ninterface DiagnosticAdapter {\n  tenantId: string\n  \n  // Required methods\n  getUserByEmail(email: string): Promise\u003cTenantUser | null\u003e\n  getEntitlements(userId: string): Promise\u003cEntitlement[]\u003e\n  getSubscription(userId: string): Promise\u003cSubscription | null\u003e\n  getProgress(userId: string): Promise\u003cProgressSummary\u003e\n  getRecentErrors(userId: string): Promise\u003cErrorLog[]\u003e\n  \n  // Optional tenant-specific\n  getMigrationStatus?(userId: string): Promise\u003cMigrationStatus\u003e  // egghead only\n  getTeamMembership?(userId: string): Promise\u003cTeamMembership\u003e    // if teams supported\n}\n\n// Normalized output - same shape regardless of tenant\ninterface UserDiagnostic {\n  tenantId: string\n  \n  user: {\n    id: string\n    email: string\n    name: string\n    createdAt: Date\n    lastLoginAt: Date\n    authProviders: string[]\n  }\n  \n  entitlements: {\n    type: string\n    source: 'subscription' | 'purchase' | 'gift' | 'team' | 'manual'\n    expiresAt: Date | null\n    isActive: boolean\n  }[]\n  \n  subscription: {\n    status: string\n    provider: 'stripe'\n    customerId: string\n    subscriptionId: string\n    currentPeriodEnd: Date\n    cancelAtPeriodEnd: boolean\n  } | null\n  \n  progress: {\n    itemsStarted: number\n    itemsCompleted: number\n    lastActivityAt: Date\n  }\n  \n  recentErrors: {\n    type: string\n    message: string\n    timestamp: Date\n  }[]\n  \n  // Tenant-specific extensions\n  extensions: Record\u003cstring, unknown\u003e\n}\n```\n\n## Tenant Adapters\n\n```typescript\n// lib/support/adapters/egghead.ts\nexport class EggheadDiagnosticAdapter implements DiagnosticAdapter {\n  tenantId = 'egghead'\n  \n  private db: PlanetScaleConnection\n  \n  async getUserByEmail(email: string) {\n    return this.db.query.users.findFirst({\n      where: eq(users.email, email)\n    })\n  }\n  \n  async getMigrationStatus(userId: string) {\n    // egghead-specific: check Rails migration status\n    return {\n      railsUserId: user.railsUserId,\n      migratedAt: user.migratedAt,\n      progressMigrated: user.progressMigrated,\n      hasDataDiscrepancy: await this.checkDiscrepancy(userId)\n    }\n  }\n  \n  // ... implement all methods\n}\n\n// lib/support/adapters/totaltypescript.ts\nexport class TotalTypeScriptDiagnosticAdapter implements DiagnosticAdapter {\n  tenantId = 'totaltypescript'\n  // Different schema, same interface\n}\n\n// Registry\nconst adapters: Record\u003cstring, DiagnosticAdapter\u003e = {\n  egghead: new EggheadDiagnosticAdapter(),\n  totaltypescript: new TotalTypeScriptDiagnosticAdapter(),\n}\n\nexport function getDiagnosticAdapter(tenantId: string): DiagnosticAdapter {\n  const adapter = adapters[tenantId]\n  if (!adapter) throw new Error(`Unknown tenant: ${tenantId}`)\n  return adapter\n}\n```\n\n## Usage in Support Flow\n\n```typescript\n// In classifier/resolver\nconst tenant = await getTenantFromInbox(inboxId)\nconst adapter = getDiagnosticAdapter(tenant.id)\nconst diagnostic = await adapter.getUserByEmail(senderEmail)\n\n// Diagnostic is normalized - resolvers don't care which tenant\nconst context = buildContext(diagnostic)\n```","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:58:46.802487-08:00","updated_at":"2025-12-11T10:03:49.942801-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.3","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T09:58:46.802822-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.4","title":"Build auto-resolver: AUTH issues (password reset, OAuth re-link)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:58:46.836826-08:00","updated_at":"2025-12-11T09:58:46.836826-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.4","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T09:58:46.837177-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.5","title":"Build auto-resolver: ACCESS issues (entitlement check, manual grant)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:58:46.870373-08:00","updated_at":"2025-12-11T09:58:46.870373-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.5","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T09:58:46.870723-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.6","title":"Build auto-resolver: PROGRESS issues (re-sync from Rails)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:58:46.902737-08:00","updated_at":"2025-12-11T09:58:46.902737-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.6","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T09:58:46.903074-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.7","title":"Build canned response generator with dynamic data injection","description":"Build canned response generator with dynamic data injection.\n\nTemplates for each issue type with placeholders:\n\n```typescript\nconst templates = {\n  auth_password_reset: {\n    subject: 'Password Reset Link Sent',\n    body: `Hi {{firstName}},\n\nI've sent a password reset link to {{email}}. Please check your inbox (and spam folder) - it should arrive within a few minutes.\n\nClick the link to set a new password and you'll be back in action.\n\nIf you don't receive it within 10 minutes, let me know and I'll look into it further.\n\nCheers,\negghead Support`\n  },\n  \n  access_restored: {\n    subject: 'Your Pro Access Has Been Restored',\n    body: `Hi {{firstName}},\n\nGood news - I've restored your Pro access. You should now be able to watch all lessons without any issues.\n\n**What happened:** {{diagnosisSummary}}\n\n**What I did:** {{actionTaken}}\n\nYour access is now active until {{accessExpiresAt}}.\n\nLet me know if you run into any other issues!\n\nCheers,\negghead Support`\n  },\n  \n  progress_resynced: {\n    subject: 'Your Course Progress Has Been Restored',\n    body: `Hi {{firstName}},\n\nI've re-synced your course progress from our records. Here's what was restored:\n\n- **Courses completed:** {{coursesCompleted}}\n- **Lessons completed:** {{lessonsCompleted}}\n- **Last activity:** {{lastActivityAt}}\n\nEverything should be back to normal now. If anything looks off, just reply to this email.\n\nCheers,\negghead Support`\n  },\n  \n  // ... more templates\n}\n\n// Injection function\nfunction generateResponse(template: string, diagnostic: UserDiagnostic, action: ActionResult) {\n  return template\n    .replace('{{firstName}}', diagnostic.user.name?.split(' ')[0] || 'there')\n    .replace('{{email}}', diagnostic.user.email)\n    .replace('{{diagnosisSummary}}', action.diagnosis)\n    .replace('{{actionTaken}}', action.summary)\n    // ... etc\n}\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:58:46.936024-08:00","updated_at":"2025-12-11T09:59:19.772625-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.7","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T09:58:46.936356-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.8","title":"Add push-button actions to Front plugin (fix auth, grant access, resync)","description":"Add push-button actions to Front plugin for support agents.\n\nNew component: MigrationActions.tsx\n\nActions available:\n1. **Fix Auth** - One click to:\n   - Send password reset email\n   - Re-link OAuth providers\n   - Clear stale sessions\n\n2. **Grant Access** - One click to:\n   - Create manual entitlement (24h, 7d, 30d, permanent)\n   - With reason field for audit trail\n\n3. **Resync Progress** - One click to:\n   - Pull progress from Rails backup\n   - Merge with Coursebuilder data\n   - Show diff before applying\n\n4. **Resync Subscription** - One click to:\n   - Fetch latest from Stripe\n   - Update local records\n   - Recalculate entitlements\n\n5. **View Full Diagnostic** - Expandable panel showing:\n   - Migration status\n   - All entitlements\n   - Subscription details\n   - Recent errors\n   - Data discrepancies\n\n6. **Generate Response** - AI-powered:\n   - Based on diagnostic + conversation\n   - Editable before sending\n   - Tracks what was auto-generated\n\n```tsx\n\u003cMigrationActions \n  email={userEmail}\n  onAction={(action, result) =\u003e {\n    // Log action for audit\n    // Update conversation tags\n    // Optionally auto-send response\n  }}\n/\u003e\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:58:46.969677-08:00","updated_at":"2025-12-11T09:59:26.559654-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.8","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T09:58:46.970033-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-1rx.9","title":"Build proactive monitor: detect users with broken state post-migration","description":"Build proactive monitor that detects broken user states BEFORE they contact support.\n\nRuns as Inngest cron (every hour during migration, daily after):\n\n```typescript\nconst proactiveMonitor = inngest.createFunction(\n  { id: 'proactive-support-monitor' },\n  { cron: '0 * * * *' }, // Every hour\n  async ({ step }) =\u003e {\n    // 1. Find users with subscription but no entitlement\n    const missingEntitlements = await step.run('check-entitlements', () =\u003e\n      db.query(`\n        SELECT u.* FROM users u\n        JOIN subscriptions s ON s.user_id = u.id\n        WHERE s.status = 'active'\n        AND NOT EXISTS (\n          SELECT 1 FROM entitlements e \n          WHERE e.user_id = u.id AND e.deleted_at IS NULL\n        )\n      `)\n    )\n    \n    // 2. Find users who logged in but hit access errors\n    const accessErrors = await step.run('check-access-errors', () =\u003e\n      getRecentErrors({ type: 'ACCESS_DENIED', since: '1 hour ago' })\n    )\n    \n    // 3. Find users with progress in Rails but not in CB\n    const missingProgress = await step.run('check-progress', () =\u003e\n      db.query(`\n        SELECT u.* FROM users u\n        WHERE u.rails_user_id IS NOT NULL\n        AND u.progress_migrated = false\n        AND u.last_login_at \u003e NOW() - INTERVAL '24 hours'\n      `)\n    )\n    \n    // 4. Auto-fix what we can\n    for (const user of missingEntitlements) {\n      await step.run(`fix-entitlement-${user.id}`, () =\u003e\n        createEntitlementFromSubscription(user)\n      )\n      await step.run(`notify-${user.id}`, () =\u003e\n        sendEmail(user, 'proactive_access_fixed')\n      )\n    }\n    \n    // 5. Alert on things we can't auto-fix\n    if (accessErrors.length \u003e 10) {\n      await step.run('alert-spike', () =\u003e\n        slack.send('#support-alerts', `âš ï¸ Access error spike: ${accessErrors.length} in last hour`)\n      )\n    }\n  }\n)\n```\n\nThis catches issues before users even notice them.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:58:46.999495-08:00","updated_at":"2025-12-11T09:59:34.922628-08:00","dependencies":[{"issue_id":"migrate-egghead-1rx.9","depends_on_id":"migrate-egghead-1rx","type":"parent-child","created_at":"2025-12-11T09:58:46.999824-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-2gb","title":"Migrate Front.com support plugin to Coursebuilder APIs","description":"The skill-front-integration submodule contains a Front.com plugin for support operations. Currently it calls Rails GraphQL/REST APIs. After migration, these need to point to Coursebuilder.\n\nCurrent capabilities (see skill-front-integration/src/trpc/router/egghead.ts):\n- getUserByEmail - lookup user by email\n- transferEmail - change user email\n- refundPurchase - process refunds via Rails API\n- transferPurchase - transfer purchase to another user\n- createCoupon - generate discount coupons\n\nPost-migration requirements:\n1. Update API endpoints from app.egghead.io to Coursebuilder\n2. Replace GraphQL calls with tRPC or REST\n3. Update Stripe account IDs in front-inboxes.json\n4. Test all support workflows end-to-end\n\nThis is P2 because support can use Stripe dashboard directly during transition.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:56:42.909587-08:00","updated_at":"2025-12-11T09:56:42.909587-08:00"}
{"id":"migrate-egghead-341","title":"Data Integrity \u0026 Safety Infrastructure","description":"Critical infrastructure for safe migration: CDC mechanism, idempotency layer, reconciliation jobs, and drift detection. Must be complete BEFORE dual-write phase begins.\n\nKey decisions:\n- CDC: Application-level dual-write with idempotency keys + reconciliation (Option C)\n- Redis Streams via Upstash for event log\n- Daily reconciliation with Slack alerts on drift","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:52:49.843078-08:00","updated_at":"2025-12-11T09:52:49.843078-08:00"}
{"id":"migrate-egghead-341.1","title":"Add stripe_event_id column to all mutation tables","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:52:49.875116-08:00","updated_at":"2025-12-11T09:52:49.875116-08:00","dependencies":[{"issue_id":"migrate-egghead-341.1","depends_on_id":"migrate-egghead-341","type":"parent-child","created_at":"2025-12-11T09:52:49.875474-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-341.2","title":"Implement webhook deduplication check in process-stripe-webhook.ts","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:52:49.907979-08:00","updated_at":"2025-12-11T09:52:49.907979-08:00","dependencies":[{"issue_id":"migrate-egghead-341.2","depends_on_id":"migrate-egghead-341","type":"parent-child","created_at":"2025-12-11T09:52:49.908305-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-341.3","title":"Add idempotency key generation for outbound Stripe API calls","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:52:49.939876-08:00","updated_at":"2025-12-11T09:52:49.939876-08:00","dependencies":[{"issue_id":"migrate-egghead-341.3","depends_on_id":"migrate-egghead-341","type":"parent-child","created_at":"2025-12-11T09:52:49.940202-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-341.4","title":"Build daily reconciliation Inngest cron (PG vs PlanetScale checksums)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:52:49.97211-08:00","updated_at":"2025-12-11T09:52:49.97211-08:00","dependencies":[{"issue_id":"migrate-egghead-341.4","depends_on_id":"migrate-egghead-341","type":"parent-child","created_at":"2025-12-11T09:52:49.972452-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-341.5","title":"Build drift detection alerts (Slack notification on divergence)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:52:50.004197-08:00","updated_at":"2025-12-11T09:52:50.004197-08:00","dependencies":[{"issue_id":"migrate-egghead-341.5","depends_on_id":"migrate-egghead-341","type":"parent-child","created_at":"2025-12-11T09:52:50.004512-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-341.6","title":"Set up Redis Streams event log for migration events","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:52:50.03716-08:00","updated_at":"2025-12-11T09:52:50.03716-08:00","dependencies":[{"issue_id":"migrate-egghead-341.6","depends_on_id":"migrate-egghead-341","type":"parent-child","created_at":"2025-12-11T09:52:50.037515-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-341.7","title":"Build rollback test: verify can flip back to Rails/Sidekiq","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:52:50.071531-08:00","updated_at":"2025-12-11T09:52:50.071531-08:00","dependencies":[{"issue_id":"migrate-egghead-341.7","depends_on_id":"migrate-egghead-341","type":"parent-child","created_at":"2025-12-11T09:52:50.071885-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-34t","title":"SEO Safety - Zero 404s Migration","description":"Protect organic traffic during migration. No 404s allowed. Staged rollout with monitoring.\n\nKey URLs to preserve:\n- /lessons/[slug] (5,132 lessons)\n- /courses/[slug] (420 courses)\n- /q/[...params] (massive sitemap from topic combinations)\n- /i/[slug] -\u003e /instructors/[slug] (134 instructors)\n\nMonitoring: Google Search Console, 404 alerts, sitemap diff","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:53:13.879743-08:00","updated_at":"2025-12-11T09:53:13.879743-08:00"}
{"id":"migrate-egghead-34t.1","title":"Generate pre-migration sitemap snapshot (all URLs)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:13.917896-08:00","updated_at":"2025-12-11T09:53:13.917896-08:00","dependencies":[{"issue_id":"migrate-egghead-34t.1","depends_on_id":"migrate-egghead-34t","type":"parent-child","created_at":"2025-12-11T09:53:13.918251-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-34t.2","title":"Build sitemap diff tool (compare pre/post migration)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:13.950193-08:00","updated_at":"2025-12-11T09:53:13.950193-08:00","dependencies":[{"issue_id":"migrate-egghead-34t.2","depends_on_id":"migrate-egghead-34t","type":"parent-child","created_at":"2025-12-11T09:53:13.95053-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-34t.3","title":"Set up Google Search Console monitoring alerts","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:13.981926-08:00","updated_at":"2025-12-11T09:53:13.981926-08:00","dependencies":[{"issue_id":"migrate-egghead-34t.3","depends_on_id":"migrate-egghead-34t","type":"parent-child","created_at":"2025-12-11T09:53:13.982248-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-34t.4","title":"Build 404 monitoring with Slack alerts (immediate notification)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:14.014244-08:00","updated_at":"2025-12-11T09:53:14.014244-08:00","dependencies":[{"issue_id":"migrate-egghead-34t.4","depends_on_id":"migrate-egghead-34t","type":"parent-child","created_at":"2025-12-11T09:53:14.014578-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-34t.5","title":"Implement staged rollout: lessons first (test 100 URLs)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:14.047078-08:00","updated_at":"2025-12-11T09:53:14.047078-08:00","dependencies":[{"issue_id":"migrate-egghead-34t.5","depends_on_id":"migrate-egghead-34t","type":"parent-child","created_at":"2025-12-11T09:53:14.047402-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-34t.6","title":"Implement staged rollout: courses second (test 50 URLs)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:14.078939-08:00","updated_at":"2025-12-11T09:53:14.078939-08:00","dependencies":[{"issue_id":"migrate-egghead-34t.6","depends_on_id":"migrate-egghead-34t","type":"parent-child","created_at":"2025-12-11T09:53:14.079292-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-34t.7","title":"Implement staged rollout: search pages last (/q/[[...all]])","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:53:14.110959-08:00","updated_at":"2025-12-11T09:53:14.110959-08:00","dependencies":[{"issue_id":"migrate-egghead-34t.7","depends_on_id":"migrate-egghead-34t","type":"parent-child","created_at":"2025-12-11T09:53:14.111352-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-34t.8","title":"Build comprehensive redirect map in next.config.ts","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:14.144386-08:00","updated_at":"2025-12-11T09:53:14.144386-08:00","dependencies":[{"issue_id":"migrate-egghead-34t.8","depends_on_id":"migrate-egghead-34t","type":"parent-child","created_at":"2025-12-11T09:53:14.144736-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-39p","title":"Kill egghead-rails and egghead-next","description":"Migrate egghead.io (699K users, 420 courses, 3M progress records) from Rails + Next.js to Coursebuilder (PlanetScale/Inngest). Kill both legacy systems.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T08:38:53.030569-08:00","updated_at":"2025-12-11T08:38:53.030569-08:00"}
{"id":"migrate-egghead-39p.1","title":"Schema design: Map Rails models to Coursebuilder","description":"","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-11T08:38:53.063791-08:00","updated_at":"2025-12-11T08:55:23.680972-08:00","closed_at":"2025-12-11T08:55:23.680972-08:00","dependencies":[{"issue_id":"migrate-egghead-39p.1","depends_on_id":"migrate-egghead-39p","type":"parent-child","created_at":"2025-12-11T08:38:53.064183-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-39p.10","title":"DNS + traffic cutover runbook","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T08:38:53.357717-08:00","updated_at":"2025-12-11T08:38:53.357717-08:00","dependencies":[{"issue_id":"migrate-egghead-39p.10","depends_on_id":"migrate-egghead-39p","type":"parent-child","created_at":"2025-12-11T08:38:53.358065-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-39p.2","title":"User/Account migration pipeline (699K users, 94K accounts)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T08:38:53.095563-08:00","updated_at":"2025-12-11T08:38:53.095563-08:00","dependencies":[{"issue_id":"migrate-egghead-39p.2","depends_on_id":"migrate-egghead-39p","type":"parent-child","created_at":"2025-12-11T08:38:53.095887-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-39p.3","title":"Subscription data migration (3,335 active)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T08:38:53.124845-08:00","updated_at":"2025-12-11T08:38:53.124845-08:00","dependencies":[{"issue_id":"migrate-egghead-39p.3","depends_on_id":"migrate-egghead-39p","type":"parent-child","created_at":"2025-12-11T08:38:53.125173-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-39p.4","title":"Progress data migration (3M records)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T08:38:53.155437-08:00","updated_at":"2025-12-11T08:38:53.155437-08:00","dependencies":[{"issue_id":"migrate-egghead-39p.4","depends_on_id":"migrate-egghead-39p","type":"parent-child","created_at":"2025-12-11T08:38:53.155764-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-39p.5","title":"Content migration: Courses, lessons, videos (97.5% on Mux)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T08:38:53.189742-08:00","updated_at":"2025-12-11T08:38:53.189742-08:00","dependencies":[{"issue_id":"migrate-egghead-39p.5","depends_on_id":"migrate-egghead-39p","type":"parent-child","created_at":"2025-12-11T08:38:53.190094-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-39p.6","title":"Stripe webhook handlers (Inngest)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T08:38:53.223268-08:00","updated_at":"2025-12-11T08:38:53.223268-08:00","dependencies":[{"issue_id":"migrate-egghead-39p.6","depends_on_id":"migrate-egghead-39p","type":"parent-child","created_at":"2025-12-11T08:38:53.223594-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-39p.7","title":"Video player + lesson view + search","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T08:38:53.256974-08:00","updated_at":"2025-12-11T08:38:53.256974-08:00","dependencies":[{"issue_id":"migrate-egghead-39p.7","depends_on_id":"migrate-egghead-39p","type":"parent-child","created_at":"2025-12-11T08:38:53.257321-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-39p.8","title":"User profiles + instructor pages","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T08:38:53.290161-08:00","updated_at":"2025-12-11T08:38:53.290161-08:00","dependencies":[{"issue_id":"migrate-egghead-39p.8","depends_on_id":"migrate-egghead-39p","type":"parent-child","created_at":"2025-12-11T08:38:53.290471-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-39p.9","title":"Auth cutover: NextAuth + OAuth migration","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T08:38:53.324795-08:00","updated_at":"2025-12-11T08:38:53.324795-08:00","dependencies":[{"issue_id":"migrate-egghead-39p.9","depends_on_id":"migrate-egghead-39p","type":"parent-child","created_at":"2025-12-11T08:38:53.325148-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5bk","title":"Phase 2: Webhook Handlers + Integration Tests","description":"Implement the STUB Inngest handlers for Stripe subscription events. Currently all 3 subscription handlers have TODO comments and no DB updates. This phase makes them production-ready with full E2E Stripe flow testing. Gate: All handlers implemented, unit tests pass, E2E checkout/cancel flows work.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:29:07.749203-08:00","updated_at":"2025-12-11T09:29:07.749203-08:00"}
{"id":"migrate-egghead-5bk.1","title":"Implement subscription.created Inngest handler (replace TODO stub)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:07.780766-08:00","updated_at":"2025-12-11T09:29:07.780766-08:00","dependencies":[{"issue_id":"migrate-egghead-5bk.1","depends_on_id":"migrate-egghead-5bk","type":"parent-child","created_at":"2025-12-11T09:29:07.781066-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5bk.2","title":"Implement subscription.updated Inngest handler (replace TODO stub)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:07.814372-08:00","updated_at":"2025-12-11T09:29:07.814372-08:00","dependencies":[{"issue_id":"migrate-egghead-5bk.2","depends_on_id":"migrate-egghead-5bk","type":"parent-child","created_at":"2025-12-11T09:29:07.814704-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5bk.3","title":"Create subscription.deleted Inngest handler (currently MISSING)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:07.848801-08:00","updated_at":"2025-12-11T09:29:07.848801-08:00","dependencies":[{"issue_id":"migrate-egghead-5bk.3","depends_on_id":"migrate-egghead-5bk","type":"parent-child","created_at":"2025-12-11T09:29:07.849128-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5bk.4","title":"Implement invoice.payment_succeeded handler with 1-min delay","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:07.882369-08:00","updated_at":"2025-12-11T09:29:07.882369-08:00","dependencies":[{"issue_id":"migrate-egghead-5bk.4","depends_on_id":"migrate-egghead-5bk","type":"parent-child","created_at":"2025-12-11T09:29:07.882705-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5bk.5","title":"Unit tests for all Inngest subscription handlers","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:07.915123-08:00","updated_at":"2025-12-11T09:29:07.915123-08:00","dependencies":[{"issue_id":"migrate-egghead-5bk.5","depends_on_id":"migrate-egghead-5bk","type":"parent-child","created_at":"2025-12-11T09:29:07.915465-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5bk.6","title":"E2E: Test Stripe checkout flow â†’ entitlement granted","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:07.948062-08:00","updated_at":"2025-12-11T09:29:07.948062-08:00","dependencies":[{"issue_id":"migrate-egghead-5bk.6","depends_on_id":"migrate-egghead-5bk","type":"parent-child","created_at":"2025-12-11T09:29:07.948409-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5bk.7","title":"E2E: Test subscription cancel â†’ access revoked","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:07.980259-08:00","updated_at":"2025-12-11T09:29:07.980259-08:00","dependencies":[{"issue_id":"migrate-egghead-5bk.7","depends_on_id":"migrate-egghead-5bk","type":"parent-child","created_at":"2025-12-11T09:29:07.980597-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5bk.8","title":"[HUMAN] Review webhook handlers + approve for shadow mode","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:08.012692-08:00","updated_at":"2025-12-11T09:29:08.012692-08:00","dependencies":[{"issue_id":"migrate-egghead-5bk.8","depends_on_id":"migrate-egghead-5bk","type":"parent-child","created_at":"2025-12-11T09:29:08.013008-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5vc","title":"Document Rails Stripe Webhook System for Next.js Migration","description":"Comprehensive analysis and documentation of egghead-rails Stripe webhook implementation including controller flow, event model, multi-tenancy, error handling, and all event types to inform migration to egghead-next","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-11T07:23:52.709294-08:00","updated_at":"2025-12-11T07:35:44.448943-08:00","closed_at":"2025-12-11T07:35:44.448943-08:00"}
{"id":"migrate-egghead-5vc.1","title":"Analyze StripeEventsController webhook flow and routing","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T07:23:52.746443-08:00","updated_at":"2025-12-11T07:32:21.645154-08:00","closed_at":"2025-12-11T07:32:21.645154-08:00","dependencies":[{"issue_id":"migrate-egghead-5vc.1","depends_on_id":"migrate-egghead-5vc","type":"parent-child","created_at":"2025-12-11T07:23:52.74676-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5vc.2","title":"Analyze StripeWebhookEvent model and persistence layer","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T07:23:52.782941-08:00","updated_at":"2025-12-11T07:32:22.898081-08:00","closed_at":"2025-12-11T07:32:22.898081-08:00","dependencies":[{"issue_id":"migrate-egghead-5vc.2","depends_on_id":"migrate-egghead-5vc","type":"parent-child","created_at":"2025-12-11T07:23:52.783247-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5vc.3","title":"Catalog all webhook event handlers and their business logic","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T07:23:52.819166-08:00","updated_at":"2025-12-11T07:32:23.805155-08:00","closed_at":"2025-12-11T07:32:23.805155-08:00","dependencies":[{"issue_id":"migrate-egghead-5vc.3","depends_on_id":"migrate-egghead-5vc","type":"parent-child","created_at":"2025-12-11T07:23:52.819483-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5vc.4","title":"Analyze multi-tenant architecture and site tenant handling","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T07:23:52.857684-08:00","updated_at":"2025-12-11T07:32:25.013428-08:00","closed_at":"2025-12-11T07:32:25.013428-08:00","dependencies":[{"issue_id":"migrate-egghead-5vc.4","depends_on_id":"migrate-egghead-5vc","type":"parent-child","created_at":"2025-12-11T07:23:52.858007-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5vc.5","title":"Map background job dependencies and async processing","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T07:23:52.894853-08:00","updated_at":"2025-12-11T07:32:25.944296-08:00","closed_at":"2025-12-11T07:32:25.944296-08:00","dependencies":[{"issue_id":"migrate-egghead-5vc.5","depends_on_id":"migrate-egghead-5vc","type":"parent-child","created_at":"2025-12-11T07:23:52.895149-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-5vc.6","title":"Synthesize findings into migration documentation","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T07:23:52.933118-08:00","updated_at":"2025-12-11T07:35:43.59652-08:00","closed_at":"2025-12-11T07:35:43.59652-08:00","dependencies":[{"issue_id":"migrate-egghead-5vc.6","depends_on_id":"migrate-egghead-5vc","type":"parent-child","created_at":"2025-12-11T07:23:52.933477-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv","title":"Phase 0: Pre-Migration Safety + E2E Infrastructure","description":"**Migration Control Plane** - The infrastructure that orchestrates everything else.\n\n## What This Phase Builds\n- **Upstash Redis** - State store, event log, pub/sub, vector DB for codebase\n- **Inngest Orchestrator** - Phase sequencing, task spawning, human checkpoints\n- **Slack Bot** - Real-time notifications, approval buttons, escalation\n- **Dashboard** - Live migration status, metrics, E2E results\n- **Playwright Infrastructure** - E2E test framework with intelligent scheduling\n- **Phase Contracts** - Explicit input/output requirements per phase\n\n## Architecture\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                 MIGRATION CONTROL PLANE                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Upstash Redis â—„â”€â”€â–º Inngest â—„â”€â”€â–º Slack Bot                  â”‚\nâ”‚       â”‚                â”‚              â”‚                      â”‚\nâ”‚       â–¼                â–¼              â–¼                      â”‚\nâ”‚  [State + Events + Vector DB] [Orchestration] [Human Loop]  â”‚\nâ”‚                        â”‚                                     â”‚\nâ”‚                        â–¼                                     â”‚\nâ”‚              Agent Swarm (Sonnet 4)                         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Gate Criteria\n- [ ] Redis connected, vector DB indexed\n- [ ] Inngest orchestrator deployed\n- [ ] Slack bot responding\n- [ ] Dashboard showing live state\n- [ ] Baseline E2E tests passing\n- [ ] Phase contracts defined for all 6 phases\n- [ ] **[HUMAN]** Joel approves control plane before Phase 1","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:28:42.08579-08:00","updated_at":"2025-12-11T09:36:47.575478-08:00"}
{"id":"migrate-egghead-6pv.1","title":"Set up Playwright E2E test infrastructure","description":"","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:42.119182-08:00","updated_at":"2025-12-11T09:38:16.90941-08:00","closed_at":"2025-12-11T09:38:16.90941-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.1","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:28:42.119511-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.10","title":"Vector DB indexing - index all 3 codebases","description":"Use Upstash Vector to index the full codebases for agent context:\n- egghead-rails (Ruby, ~50K LOC)\n- egghead-next (TypeScript, ~100K LOC)  \n- course-builder (TypeScript, ~200K LOC)\n- Create embeddings for all source files\n- Build semantic search API for agents to query\n- Test retrieval quality with sample queries","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:38:30.43257-08:00","updated_at":"2025-12-11T09:38:30.43257-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.10","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:38:30.432972-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.11","title":"Inngest orchestrator functions - phase sequencing, task spawning","description":"Build the Inngest orchestration layer:\n- migrationOrchestrator function (phase sequencing)\n- taskExecutor function (agent task execution)\n- Human checkpoint wait/approval flow\n- E2E validation triggers\n- Retry logic with exponential backoff\n- Event emission for all state transitions\n- Integration with Redis state store","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:38:32.935738-08:00","updated_at":"2025-12-11T09:38:32.935738-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.11","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:38:32.936111-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.12","title":"Slack bot - #egghead-migration channel, approval buttons","description":"Build Slack integration for human-in-the-loop:\n- Create #egghead-migration channel\n- Build Slack bot with Block Kit UI\n- Phase start/complete notifications\n- Human checkpoint approval buttons (Approve/Reject)\n- Task failure alerts with error context\n- E2E failure notifications\n- Link to dashboard in all messages\n- Inngest function to handle Slack events","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:38:36.028934-08:00","updated_at":"2025-12-11T09:38:36.028934-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.12","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:38:36.029327-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.13","title":"Dashboard - live migration status, metrics, E2E results","description":"Build real-time migration dashboard:\n- Phase progress visualization (7 phases)\n- Task status per phase (pending/in_progress/completed/failed)\n- Metrics display (users migrated, subs, progress records)\n- E2E test results with failure details\n- Event log timeline\n- Human checkpoint status\n- Redis-backed real-time updates\nLocation TBD: standalone app or part of egghead Coursebuilder app","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:38:39.221168-08:00","updated_at":"2025-12-11T09:38:39.221168-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.13","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:38:39.221486-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.14","title":"Playwright infrastructure - E2E framework with intelligent scheduling","description":"Set up Playwright E2E testing infrastructure:\n- playwright.config.ts for egghead Coursebuilder app\n- Test fixtures and helpers\n- Auth flow testing (login, logout, session)\n- Content rendering tests (courses, lessons)\n- Subscription/entitlement tests\n- Intelligent scheduling (not after every task, batch at phase boundaries)\n- CI integration for automated runs\n- Screenshot/video capture on failure","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:38:42.362007-08:00","updated_at":"2025-12-11T09:38:42.362007-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.14","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:38:42.362377-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.15","title":"Phase contracts - define input/output for all 6 phases","description":"Define explicit contracts for each migration phase:\n- Phase 1: Data Migration (users, orgs, subs, content, progress)\n- Phase 2: Webhook Handlers (Stripe Inngest functions)\n- Phase 3: Cron Jobs (17 Sidekiq â†’ Inngest)\n- Phase 4: External Integrations (Customer.io, mailers)\n- Phase 5: UI Components + E2E Click Matrix\n- Phase 6: Cutover + Final Validation\n\nEach contract includes:\n- Required inputs (files, data, previous phase completion)\n- Validators (DB connections, file existence)\n- Output artifacts (files, reports)\n- Metrics to capture\n- E2E tests that must pass\n- Human checkpoint criteria (if any)","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:38:47.381551-08:00","updated_at":"2025-12-11T09:38:47.381551-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.15","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:38:47.381935-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.16","title":"Baseline E2E tests - validate current egghead.io state","description":"Create baseline E2E tests against current production:\n- Homepage loads correctly\n- Course pages render (sample 5 courses)\n- Lesson pages render with video player\n- Search works\n- Auth flow (if testable)\n- Instructor pages load\n- Tag/topic pages load\nThese establish the \"before\" state for comparison after migration.","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:38:50.51997-08:00","updated_at":"2025-12-11T09:38:50.51997-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.16","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:38:50.520329-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.17","title":"[HUMAN] Approve Migration Control Plane before Phase 1","description":"Human gate before starting data migration:\n- [ ] Redis connected and state schema working\n- [ ] Vector DB indexed with all 3 codebases\n- [ ] Inngest orchestrator deployed and tested\n- [ ] Slack bot responding in #egghead-migration\n- [ ] Dashboard showing live state\n- [ ] Baseline E2E tests passing\n- [ ] Phase contracts reviewed and approved\n- [ ] Joel signs off on control plane architecture","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:38:52.8783-08:00","updated_at":"2025-12-11T09:38:52.8783-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.17","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:38:52.878653-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.2","title":"Create E2E click-test matrix document","description":"","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:42.154291-08:00","updated_at":"2025-12-11T09:38:17.472045-08:00","closed_at":"2025-12-11T09:38:17.472045-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.2","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:28:42.154625-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.3","title":"Build baseline E2E tests for current state","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T09:28:42.185782-08:00","updated_at":"2025-12-11T09:38:17.984763-08:00","closed_at":"2025-12-11T09:38:17.984763-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.3","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:28:42.186126-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.4","title":"Design CDC mechanism (ADR)","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T09:28:42.217548-08:00","updated_at":"2025-12-11T09:38:18.570713-08:00","closed_at":"2025-12-11T09:38:18.570713-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.4","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:28:42.217874-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.5","title":"Build idempotency layer for migrations","description":"","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:42.248996-08:00","updated_at":"2025-12-11T09:38:19.019968-08:00","closed_at":"2025-12-11T09:38:19.019968-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.5","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:28:42.249305-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.6","title":"Build reconciliation job infrastructure","description":"","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:42.28041-08:00","updated_at":"2025-12-11T09:38:19.444461-08:00","closed_at":"2025-12-11T09:38:19.444461-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.6","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:28:42.280739-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.7","title":"Document and test rollback procedures","description":"","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:42.313269-08:00","updated_at":"2025-12-11T09:38:20.067897-08:00","closed_at":"2025-12-11T09:38:20.067897-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.7","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:28:42.313601-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.8","title":"[HUMAN] Review and approve pre-migration safety plan","description":"","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:42.349229-08:00","updated_at":"2025-12-11T09:38:20.536458-08:00","closed_at":"2025-12-11T09:38:20.536458-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.8","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:28:42.349565-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6pv.9","title":"Upstash Redis setup - state store, event log, pub/sub","description":"Set up Upstash Redis for the Migration Control Plane:\n- Create Upstash Redis instance\n- Configure state store schema (MigrationState interface)\n- Set up Redis Streams for event log (migration:events)\n- Configure pub/sub channels for real-time notifications\n- Create helper functions for state queries and updates\n- Test connection from local dev and Vercel","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:38:27.672978-08:00","updated_at":"2025-12-11T09:38:27.672978-08:00","dependencies":[{"issue_id":"migrate-egghead-6pv.9","depends_on_id":"migrate-egghead-6pv","type":"parent-child","created_at":"2025-12-11T09:38:27.673359-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6y2","title":"Testing Infrastructure: Full Pyramid Coverage","description":"**NO CODE SHIPS WITHOUT TESTS. PERIOD.**\n\nEvery single piece of this migration gets the full testing pyramid - but we're pragmatic about it.\n\n```\n                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                    â”‚   E2E/UI    â”‚  â† Playwright: real browser, real flows\n                    â”‚  (few, slow)â”‚\n                   â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€\n                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                  â”‚  Integration    â”‚  â† REAL services: Stripe test mode, real DB, real Redis\n                  â”‚  (some, medium) â”‚     NO MOCKS for external services\n                 â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€\n                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                â”‚      Unit Tests       â”‚  â† Pure functions, transforms, validators\n                â”‚    (many, fast)       â”‚     Mock only internal boundaries\n                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Philosophy: Real \u003e Mock\n\n**Stripe mocks are garbage.** They don't behave like real Stripe. Use:\n- **Stripe Test Mode** for integration tests (real API, test data)\n- **Stripe CLI** for webhook forwarding in E2E\n- **Stripe Test Clocks** for time-based scenarios (renewals, trials)\n\n**Mock only what you own.** Don't mock:\n- Stripe API â†’ use test mode\n- Database â†’ use real MySQL (Testcontainers or PlanetScale branch)\n- Redis â†’ use real Redis (Testcontainers or Upstash)\n- Inngest â†’ use dev server\n\n**Do mock:**\n- Your own service boundaries (when testing a single unit)\n- OpenAI (expensive, rate-limited) â†’ mock with deterministic responses\n- Front API (no test mode) â†’ mock the HTTP layer\n\n## CI Strategy: Fast Feedback, Real Tests\n\n```\nPush to branch:\nâ”œâ”€ Lint + Typecheck (30s)           â† Instant feedback\nâ”œâ”€ Unit tests (1-2min)              â† Fast, parallel\nâ””â”€ Integration tests (3-5min)       â† Real DB, real Stripe test mode\n\nPR to main:\nâ”œâ”€ All above +\nâ”œâ”€ E2E critical paths (5-10min)     â† Playwright\nâ””â”€ Coverage check                   â† 80% gate\n\nMerge to main:\nâ”œâ”€ Full E2E suite                   â† All browsers\nâ””â”€ Deploy to preview                â† Vercel preview URL\n```\n\n## What We're NOT Doing\n\n- âŒ stripe-mock (unreliable, doesn't match real behavior)\n- âŒ Mocking database queries (use real DB)\n- âŒ Mocking Redis (use real Redis)\n- âŒ Running full E2E on every push (too slow)\n- âŒ 100% coverage targets (diminishing returns)\n- âŒ Flaky test tolerance (fix or delete)\n\n## Coverage Requirements\n\n| Layer | Target | Notes |\n|-------|--------|-------|\n| Unit | 80%+ lines | Pure functions, transforms |\n| Integration | Critical paths | Auth, payments, subscriptions |\n| E2E | Happy paths + key errors | Login, checkout, video playback |\n\n## Test Data Strategy\n\n- **Stripe**: Real test mode with cleanup after each test\n- **Database**: PlanetScale branch databases OR Testcontainers\n- **Fixtures**: Deterministic data for unit tests\n- **Factories**: faker-based for integration tests\n- **Seeds**: Known state for E2E","status":"open","priority":0,"issue_type":"epic","created_at":"2025-12-11T10:04:56.340337-08:00","updated_at":"2025-12-11T10:07:39.791469-08:00"}
{"id":"migrate-egghead-6y2.1","title":"Set up Vitest + testing infrastructure","description":"Set up the core testing infrastructure that everything else builds on.\n\n## Vitest Configuration\n\n```typescript\n// vitest.config.ts\nimport { defineConfig } from 'vitest/config'\nimport react from '@vitejs/plugin-react'\nimport tsconfigPaths from 'vite-tsconfig-paths'\n\nexport default defineConfig({\n  plugins: [react(), tsconfigPaths()],\n  test: {\n    // Test environments\n    environment: 'node',\n    environmentMatchGlobs: [\n      ['**/*.dom.test.{ts,tsx}', 'jsdom'],\n      ['**/*.component.test.{ts,tsx}', 'jsdom'],\n    ],\n    \n    // Coverage\n    coverage: {\n      provider: 'v8',\n      reporter: ['text', 'json', 'html'],\n      exclude: [\n        'node_modules/',\n        '**/*.test.ts',\n        '**/__mocks__/',\n        '**/__fixtures__/',\n      ],\n      thresholds: {\n        statements: 80,\n        branches: 80,\n        functions: 80,\n        lines: 80,\n      },\n    },\n    \n    // Test organization\n    include: [\n      '**/*.test.ts',\n      '**/*.test.tsx',\n    ],\n    \n    // Separate test pools\n    poolOptions: {\n      threads: {\n        singleThread: true, // For DB tests\n      },\n    },\n    \n    // Setup files\n    setupFiles: [\n      './test/setup.ts',\n    ],\n    \n    // Global test utilities\n    globals: true,\n  },\n})\n```\n\n## Directory Structure\n\n```\ntest/\nâ”œâ”€â”€ setup.ts                 # Global setup (env, mocks)\nâ”œâ”€â”€ utils/\nâ”‚   â”œâ”€â”€ db.ts               # Test DB helpers\nâ”‚   â”œâ”€â”€ redis.ts            # Test Redis helpers\nâ”‚   â”œâ”€â”€ stripe.ts           # Stripe mock helpers\nâ”‚   â”œâ”€â”€ inngest.ts          # Inngest test helpers\nâ”‚   â””â”€â”€ factories/          # Data factories\nâ”‚       â”œâ”€â”€ user.ts\nâ”‚       â”œâ”€â”€ subscription.ts\nâ”‚       â””â”€â”€ ...\nâ”œâ”€â”€ fixtures/\nâ”‚   â”œâ”€â”€ users.json\nâ”‚   â”œâ”€â”€ stripe-events/\nâ”‚   â”‚   â”œâ”€â”€ checkout.completed.json\nâ”‚   â”‚   â”œâ”€â”€ subscription.created.json\nâ”‚   â”‚   â””â”€â”€ ...\nâ”‚   â””â”€â”€ ...\nâ””â”€â”€ integration/\n    â”œâ”€â”€ setup.ts            # Testcontainers setup\n    â””â”€â”€ globalSetup.ts      # Start containers once\n```\n\n## Package.json Scripts\n\n```json\n{\n  \"scripts\": {\n    \"test\": \"vitest\",\n    \"test:unit\": \"vitest --project unit\",\n    \"test:integration\": \"vitest --project integration\",\n    \"test:e2e\": \"playwright test\",\n    \"test:coverage\": \"vitest --coverage\",\n    \"test:ci\": \"vitest --run --coverage\"\n  }\n}\n```\n\n## Test Naming Convention\n\n```\n*.test.ts          - Unit tests\n*.integration.ts   - Integration tests (real DB/Redis)\n*.e2e.ts          - E2E tests (Playwright)\n*.component.ts    - React component tests\n```\n\n## Implementation\n\n1. Install deps: vitest, @vitest/coverage-v8, @testing-library/react\n2. Create vitest.config.ts with workspaces\n3. Create test/setup.ts with global mocks\n4. Create test/utils/ helpers\n5. Create initial factories\n6. Add CI workflow for tests\n7. Add pre-commit hook for affected tests","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T10:05:19.35957-08:00","updated_at":"2025-12-11T10:05:19.35957-08:00","dependencies":[{"issue_id":"migrate-egghead-6y2.1","depends_on_id":"migrate-egghead-6y2","type":"parent-child","created_at":"2025-12-11T10:05:19.359988-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6y2.2","title":"Set up Testcontainers for integration tests (MySQL, Redis)","description":"Set up Testcontainers for real database/Redis integration tests.\n\n## Why Testcontainers\n\n- Real MySQL (not SQLite pretending to be MySQL)\n- Real Redis (not in-memory mock)\n- Isolated per test run\n- Same behavior as production\n- Works in CI\n\n## Setup\n\n```typescript\n// test/integration/setup.ts\nimport { MySqlContainer, StartedMySqlContainer } from '@testcontainers/mysql'\nimport { RedisContainer, StartedRedisContainer } from '@testcontainers/redis'\nimport { drizzle } from 'drizzle-orm/mysql2'\nimport mysql from 'mysql2/promise'\nimport { Redis } from '@upstash/redis'\n\nlet mysqlContainer: StartedMySqlContainer\nlet redisContainer: StartedRedisContainer\n\nexport async function setupTestContainers() {\n  // Start MySQL\n  mysqlContainer = await new MySqlContainer('mysql:8.0')\n    .withDatabase('test')\n    .withUsername('test')\n    .withUserPassword('test')\n    .start()\n  \n  // Start Redis\n  redisContainer = await new RedisContainer('redis:7')\n    .start()\n  \n  // Set env vars for tests\n  process.env.DATABASE_URL = mysqlContainer.getConnectionUri()\n  process.env.UPSTASH_REDIS_REST_URL = `http://${redisContainer.getHost()}:${redisContainer.getPort()}`\n  \n  // Run migrations\n  const connection = await mysql.createConnection(mysqlContainer.getConnectionUri())\n  const db = drizzle(connection)\n  await migrate(db, { migrationsFolder: './drizzle' })\n  \n  return { mysqlContainer, redisContainer }\n}\n\nexport async function teardownTestContainers() {\n  await mysqlContainer?.stop()\n  await redisContainer?.stop()\n}\n\n// Per-test cleanup\nexport async function resetDatabase(db: DrizzleDB) {\n  // Truncate all tables in correct order (FK constraints)\n  await db.execute(sql`SET FOREIGN_KEY_CHECKS = 0`)\n  for (const table of ['purchases', 'subscriptions', 'users', ...]) {\n    await db.execute(sql`TRUNCATE TABLE ${sql.identifier(table)}`)\n  }\n  await db.execute(sql`SET FOREIGN_KEY_CHECKS = 1`)\n}\n```\n\n## Global Setup (run once)\n\n```typescript\n// test/integration/globalSetup.ts\nimport { setupTestContainers, teardownTestContainers } from './setup'\n\nexport async function setup() {\n  const containers = await setupTestContainers()\n  return () =\u003e teardownTestContainers()\n}\n```\n\n## Vitest Config for Integration\n\n```typescript\n// vitest.config.integration.ts\nexport default defineConfig({\n  test: {\n    include: ['**/*.integration.ts'],\n    globalSetup: './test/integration/globalSetup.ts',\n    setupFiles: ['./test/integration/setup.ts'],\n    pool: 'forks',  // Isolated processes\n    poolOptions: {\n      forks: {\n        singleFork: true,  // Share containers\n      },\n    },\n    testTimeout: 30000,  // Containers can be slow\n  },\n})\n```\n\n## Usage in Tests\n\n```typescript\n// src/lib/subscriptions.integration.ts\nimport { describe, it, expect, beforeEach } from 'vitest'\nimport { getTestDb, resetDatabase } from '@/test/integration/setup'\nimport { createSubscription } from './subscriptions'\n\ndescribe('Subscriptions (integration)', () =\u003e {\n  const db = getTestDb()\n  \n  beforeEach(async () =\u003e {\n    await resetDatabase(db)\n  })\n  \n  it('creates subscription with correct entitlements', async () =\u003e {\n    // This hits REAL MySQL\n    const sub = await createSubscription({\n      userId: 'user_123',\n      stripeSubscriptionId: 'sub_xxx',\n      priceId: 'price_pro_monthly',\n    })\n    \n    expect(sub.status).toBe('active')\n    \n    // Verify DB state\n    const entitlements = await db.query.entitlements.findMany({\n      where: eq(entitlements.userId, 'user_123')\n    })\n    expect(entitlements).toHaveLength(1)\n    expect(entitlements[0].type).toBe('pro')\n  })\n})\n```\n\n## CI Configuration\n\n```yaml\n# .github/workflows/test.yml\nintegration:\n  runs-on: ubuntu-latest\n  services:\n    # Testcontainers handles this, but we need Docker\n    docker:\n      image: docker:dind\n  steps:\n    - uses: actions/checkout@v4\n    - uses: actions/setup-node@v4\n    - run: pnpm install\n    - run: pnpm test:integration\n```","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T10:05:38.591731-08:00","updated_at":"2025-12-11T10:05:38.591731-08:00","dependencies":[{"issue_id":"migrate-egghead-6y2.2","depends_on_id":"migrate-egghead-6y2","type":"parent-child","created_at":"2025-12-11T10:05:38.592146-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6y2.3","title":"Set up Playwright for E2E tests","description":"Set up Playwright for full E2E browser testing.\n\n## Playwright Configuration\n\n```typescript\n// playwright.config.ts\nimport { defineConfig, devices } from '@playwright/test'\n\nexport default defineConfig({\n  testDir: './e2e',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  reporter: [\n    ['html'],\n    ['json', { outputFile: 'test-results/results.json' }],\n    process.env.CI ? ['github'] : ['list'],\n  ],\n  \n  use: {\n    baseURL: 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n    video: 'on-first-retry',\n  },\n  \n  projects: [\n    // Auth setup - runs first\n    { name: 'setup', testMatch: /.*\\.setup\\.ts/ },\n    \n    {\n      name: 'chromium',\n      use: { ...devices['Desktop Chrome'] },\n      dependencies: ['setup'],\n    },\n    {\n      name: 'firefox',\n      use: { ...devices['Desktop Firefox'] },\n      dependencies: ['setup'],\n    },\n    {\n      name: 'mobile',\n      use: { ...devices['iPhone 13'] },\n      dependencies: ['setup'],\n    },\n  ],\n  \n  // Start dev server for tests\n  webServer: {\n    command: 'pnpm dev',\n    url: 'http://localhost:3000',\n    reuseExistingServer: !process.env.CI,\n    timeout: 120000,\n  },\n})\n```\n\n## Directory Structure\n\n```\ne2e/\nâ”œâ”€â”€ auth.setup.ts           # Create auth state\nâ”œâ”€â”€ fixtures/\nâ”‚   â”œâ”€â”€ test-user.ts        # Test user factory\nâ”‚   â””â”€â”€ ...\nâ”œâ”€â”€ pages/                  # Page Object Models\nâ”‚   â”œâ”€â”€ login.page.ts\nâ”‚   â”œâ”€â”€ lesson.page.ts\nâ”‚   â”œâ”€â”€ checkout.page.ts\nâ”‚   â””â”€â”€ ...\nâ”œâ”€â”€ auth/\nâ”‚   â”œâ”€â”€ login.e2e.ts\nâ”‚   â”œâ”€â”€ oauth.e2e.ts\nâ”‚   â””â”€â”€ ...\nâ”œâ”€â”€ subscriptions/\nâ”‚   â”œâ”€â”€ checkout.e2e.ts\nâ”‚   â”œâ”€â”€ cancel.e2e.ts\nâ”‚   â””â”€â”€ ...\nâ”œâ”€â”€ content/\nâ”‚   â”œâ”€â”€ lesson-playback.e2e.ts\nâ”‚   â”œâ”€â”€ course-progress.e2e.ts\nâ”‚   â””â”€â”€ ...\nâ””â”€â”€ support/\n    â”œâ”€â”€ ticket-flow.e2e.ts\n    â””â”€â”€ ...\n```\n\n## Page Object Model Example\n\n```typescript\n// e2e/pages/lesson.page.ts\nimport { Page, Locator } from '@playwright/test'\n\nexport class LessonPage {\n  readonly page: Page\n  readonly videoPlayer: Locator\n  readonly completeButton: Locator\n  readonly nextLessonButton: Locator\n  readonly progressBar: Locator\n  \n  constructor(page: Page) {\n    this.page = page\n    this.videoPlayer = page.locator('[data-testid=\"video-player\"]')\n    this.completeButton = page.locator('[data-testid=\"complete-lesson\"]')\n    this.nextLessonButton = page.locator('[data-testid=\"next-lesson\"]')\n    this.progressBar = page.locator('[data-testid=\"progress-bar\"]')\n  }\n  \n  async goto(slug: string) {\n    await this.page.goto(`/lessons/${slug}`)\n  }\n  \n  async waitForVideoReady() {\n    await this.videoPlayer.waitFor({ state: 'visible' })\n    await this.page.waitForFunction(() =\u003e {\n      const video = document.querySelector('video')\n      return video \u0026\u0026 video.readyState \u003e= 3\n    })\n  }\n  \n  async markComplete() {\n    await this.completeButton.click()\n    await this.page.waitForResponse(resp =\u003e \n      resp.url().includes('/api/progress') \u0026\u0026 resp.status() === 200\n    )\n  }\n  \n  async getProgress(): Promise\u003cnumber\u003e {\n    const width = await this.progressBar.evaluate(el =\u003e \n      getComputedStyle(el).getPropertyValue('--progress')\n    )\n    return parseFloat(width)\n  }\n}\n```\n\n## Auth Setup (reusable auth state)\n\n```typescript\n// e2e/auth.setup.ts\nimport { test as setup, expect } from '@playwright/test'\n\nconst authFile = 'e2e/.auth/user.json'\n\nsetup('authenticate', async ({ page }) =\u003e {\n  // Login as test user\n  await page.goto('/login')\n  await page.fill('[name=\"email\"]', process.env.TEST_USER_EMAIL!)\n  await page.fill('[name=\"password\"]', process.env.TEST_USER_PASSWORD!)\n  await page.click('[type=\"submit\"]')\n  \n  // Wait for auth to complete\n  await page.waitForURL('/dashboard')\n  \n  // Save auth state\n  await page.context().storageState({ path: authFile })\n})\n```\n\n## Example E2E Test\n\n```typescript\n// e2e/content/lesson-playback.e2e.ts\nimport { test, expect } from '@playwright/test'\nimport { LessonPage } from '../pages/lesson.page'\n\ntest.describe('Lesson Playback', () =\u003e {\n  test('pro user can watch full lesson and mark complete', async ({ page }) =\u003e {\n    const lessonPage = new LessonPage(page)\n    \n    await lessonPage.goto('intro-to-typescript')\n    await lessonPage.waitForVideoReady()\n    \n    // Video should be playable (not gated)\n    await expect(lessonPage.videoPlayer).toBeVisible()\n    await expect(page.locator('[data-testid=\"paywall\"]')).not.toBeVisible()\n    \n    // Mark complete\n    await lessonPage.markComplete()\n    \n    // Progress should update\n    const progress = await lessonPage.getProgress()\n    expect(progress).toBeGreaterThan(0)\n  })\n  \n  test('free user sees paywall after preview', async ({ browser }) =\u003e {\n    // Use fresh context (no auth)\n    const context = await browser.newContext()\n    const page = await context.newPage()\n    const lessonPage = new LessonPage(page)\n    \n    await lessonPage.goto('advanced-patterns')\n    \n    // Should see paywall\n    await expect(page.locator('[data-testid=\"paywall\"]')).toBeVisible()\n    await expect(lessonPage.completeButton).not.toBeVisible()\n  })\n})\n```\n\n## CI Integration\n\n```yaml\ne2e:\n  runs-on: ubuntu-latest\n  steps:\n    - uses: actions/checkout@v4\n    - uses: actions/setup-node@v4\n    - run: pnpm install\n    - run: pnpm exec playwright install --with-deps\n    - run: pnpm test:e2e\n    - uses: actions/upload-artifact@v4\n      if: failure()\n      with:\n        name: playwright-report\n        path: playwright-report/\n```","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T10:05:51.848159-08:00","updated_at":"2025-12-11T10:05:51.848159-08:00","dependencies":[{"issue_id":"migrate-egghead-6y2.3","depends_on_id":"migrate-egghead-6y2","type":"parent-child","created_at":"2025-12-11T10:05:51.84856-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6y2.4","title":"Set up Stripe testing infrastructure (stripe-mock + CLI)","description":"Set up Stripe testing using REAL Stripe test mode - no mocks.\n\n## Why No stripe-mock\n\nstripe-mock is fundamentally broken:\n- Doesn't validate request bodies properly\n- Doesn't maintain state between calls\n- Webhook signatures don't match real behavior\n- Edge cases behave differently than production\n- False confidence - tests pass but prod breaks\n\n## Real Stripe Test Mode Strategy\n\n### 1. Test Mode API (Integration Tests)\n\n```typescript\n// test/utils/stripe.ts\nimport Stripe from 'stripe'\n\n// Real Stripe, test mode\nexport const stripe = new Stripe(process.env.STRIPE_SECRET_KEY_TEST!, {\n  apiVersion: '2024-11-20.acacia',\n})\n\n// Create isolated test data\nexport async function createTestCustomer(email?: string) {\n  return stripe.customers.create({\n    email: email ?? `test-${Date.now()}@example.com`,\n    metadata: { \n      test: 'true',\n      createdBy: 'integration-test',\n      createdAt: new Date().toISOString(),\n    },\n  })\n}\n\n// Cleanup after tests\nexport async function cleanupTestCustomer(customerId: string) {\n  try {\n    // Cancel any subscriptions first\n    const subs = await stripe.subscriptions.list({ customer: customerId })\n    for (const sub of subs.data) {\n      await stripe.subscriptions.cancel(sub.id)\n    }\n    // Delete customer\n    await stripe.customers.del(customerId)\n  } catch (e) {\n    // Already deleted, fine\n  }\n}\n```\n\n### 2. Test Clocks (Time-Based Scenarios)\n\n```typescript\n// For testing renewals, trials, cancellations\nexport async function createTestClockCustomer() {\n  const testClock = await stripe.testHelpers.testClocks.create({\n    frozen_time: Math.floor(Date.now() / 1000),\n    name: `test-clock-${Date.now()}`,\n  })\n  \n  const customer = await stripe.customers.create({\n    email: `clock-test-${Date.now()}@example.com`,\n    test_clock: testClock.id,\n    metadata: { test: 'true' },\n  })\n  \n  return { testClock, customer }\n}\n\n// Advance time to trigger renewal\nexport async function advanceTestClock(testClockId: string, seconds: number) {\n  const clock = await stripe.testHelpers.testClocks.retrieve(testClockId)\n  await stripe.testHelpers.testClocks.advance(testClockId, {\n    frozen_time: clock.frozen_time + seconds,\n  })\n  \n  // Wait for Stripe to process\n  await new Promise(resolve =\u003e setTimeout(resolve, 2000))\n}\n```\n\n### 3. Webhook Testing with Stripe CLI\n\n```typescript\n// e2e/utils/stripe-webhooks.ts\nimport { spawn, ChildProcess } from 'child_process'\n\nlet stripeProcess: ChildProcess | null = null\n\nexport async function startStripeWebhooks(port = 3000) {\n  return new Promise\u003cstring\u003e((resolve, reject) =\u003e {\n    stripeProcess = spawn('stripe', [\n      'listen',\n      '--forward-to', `localhost:${port}/api/webhooks/stripe`,\n      '--skip-verify',  // For local dev\n    ])\n    \n    stripeProcess.stdout?.on('data', (data) =\u003e {\n      const output = data.toString()\n      // Extract webhook signing secret\n      const match = output.match(/whsec_[a-zA-Z0-9]+/)\n      if (match) {\n        process.env.STRIPE_WEBHOOK_SECRET = match[0]\n        resolve(match[0])\n      }\n    })\n    \n    stripeProcess.stderr?.on('data', (data) =\u003e {\n      console.error('Stripe CLI:', data.toString())\n    })\n    \n    setTimeout(() =\u003e reject(new Error('Stripe CLI timeout')), 10000)\n  })\n}\n\nexport function stopStripeWebhooks() {\n  stripeProcess?.kill()\n  stripeProcess = null\n}\n```\n\n### 4. Integration Test Example\n\n```typescript\n// src/inngest/stripe/subscription-lifecycle.integration.ts\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest'\nimport { stripe, createTestCustomer, cleanupTestCustomer } from '@/test/utils/stripe'\nimport { getTestDb, resetDatabase } from '@/test/integration/setup'\n\ndescribe('Subscription Lifecycle (real Stripe)', () =\u003e {\n  const db = getTestDb()\n  let testCustomerId: string\n  \n  beforeEach(async () =\u003e {\n    await resetDatabase(db)\n    const customer = await createTestCustomer()\n    testCustomerId = customer.id\n    \n    // Create user linked to Stripe customer\n    await db.insert(users).values({\n      id: 'user_test',\n      email: customer.email!,\n      stripeCustomerId: customer.id,\n    })\n  })\n  \n  afterEach(async () =\u003e {\n    await cleanupTestCustomer(testCustomerId)\n  })\n  \n  it('creates subscription and entitlements on checkout', async () =\u003e {\n    // Create real subscription in Stripe\n    const subscription = await stripe.subscriptions.create({\n      customer: testCustomerId,\n      items: [{ price: process.env.STRIPE_PRICE_PRO_MONTHLY! }],\n      payment_behavior: 'default_incomplete',\n      payment_settings: { save_default_payment_method: 'on_subscription' },\n      expand: ['latest_invoice.payment_intent'],\n    })\n    \n    // Simulate successful payment (test mode auto-succeeds with test cards)\n    const invoice = subscription.latest_invoice as Stripe.Invoice\n    const paymentIntent = invoice.payment_intent as Stripe.PaymentIntent\n    \n    await stripe.paymentIntents.confirm(paymentIntent.id, {\n      payment_method: 'pm_card_visa',  // Test card\n    })\n    \n    // Wait for webhook to process (real webhook via Stripe CLI or poll)\n    await waitForCondition(async () =\u003e {\n      const sub = await db.query.subscriptions.findFirst({\n        where: eq(subscriptions.stripeSubscriptionId, subscription.id),\n      })\n      return sub?.status === 'active'\n    }, { timeout: 10000 })\n    \n    // Verify DB state\n    const dbSub = await db.query.subscriptions.findFirst({\n      where: eq(subscriptions.stripeSubscriptionId, subscription.id),\n    })\n    expect(dbSub).toBeDefined()\n    expect(dbSub!.status).toBe('active')\n    \n    const entitlements = await db.query.entitlements.findMany({\n      where: eq(entitlements.userId, 'user_test'),\n    })\n    expect(entitlements).toHaveLength(1)\n    expect(entitlements[0].type).toBe('pro')\n  })\n})\n```\n\n## CI Configuration\n\n```yaml\nintegration:\n  env:\n    STRIPE_SECRET_KEY_TEST: ${{ secrets.STRIPE_SECRET_KEY_TEST }}\n    STRIPE_PRICE_PRO_MONTHLY: ${{ secrets.STRIPE_PRICE_PRO_MONTHLY }}\n  steps:\n    - run: pnpm test:integration\n    # No stripe-mock needed - we hit real Stripe test mode\n```\n\n## Test Isolation\n\nEach test creates its own Stripe customer and cleans up after. No shared state between tests. Tests can run in parallel safely.","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T10:06:13.546127-08:00","updated_at":"2025-12-11T10:08:30.366551-08:00","dependencies":[{"issue_id":"migrate-egghead-6y2.4","depends_on_id":"migrate-egghead-6y2","type":"parent-child","created_at":"2025-12-11T10:06:13.546549-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6y2.5","title":"Set up Inngest testing (@inngest/test)","description":"Set up Inngest function testing at all levels.\n\n## @inngest/test Package\n\n```typescript\n// test/utils/inngest.ts\nimport { createStepTools } from '@inngest/test'\nimport { inngest } from '@/inngest/client'\n\nexport function createTestContext() {\n  const stepTools = createStepTools()\n  \n  return {\n    ...stepTools,\n    inngest,\n  }\n}\n```\n\n## Unit Testing Inngest Functions\n\n```typescript\n// src/inngest/support/classify-issue.test.ts\nimport { describe, it, expect, vi } from 'vitest'\nimport { classifyIssue } from './classify-issue'\nimport { createTestContext } from '@/test/utils/inngest'\n\ndescribe('classifyIssue', () =\u003e {\n  it('classifies auth issues correctly', async () =\u003e {\n    const { runStep, getStepOutput } = createTestContext()\n    \n    const event = {\n      name: 'support/conversation.received',\n      data: {\n        tenantId: 'egghead',\n        conversationId: 'conv_123',\n        email: 'user@example.com',\n        subject: 'Cannot log in',\n        body: 'I keep getting an error when trying to sign in with GitHub',\n      },\n    }\n    \n    // Mock the OpenAI call\n    vi.mock('@/lib/openai', () =\u003e ({\n      classifyWithAI: vi.fn().mockResolvedValue({\n        category: 'AUTH',\n        specificIssue: 'oauth_github',\n        urgency: 'medium',\n        canAutoResolve: true,\n      }),\n    }))\n    \n    await runStep(classifyIssue, event, 'classify')\n    \n    const classification = getStepOutput('classify')\n    expect(classification.category).toBe('AUTH')\n    expect(classification.specificIssue).toBe('oauth_github')\n  })\n  \n  it('routes to correct resolver after classification', async () =\u003e {\n    const { runFunction, getSentEvents } = createTestContext()\n    \n    const event = {\n      name: 'support/conversation.received',\n      data: {\n        tenantId: 'egghead',\n        conversationId: 'conv_123',\n        email: 'user@example.com',\n        subject: 'Lost my progress',\n        body: 'All my completed lessons are gone',\n      },\n    }\n    \n    await runFunction(classifyIssue, event)\n    \n    const sentEvents = getSentEvents()\n    expect(sentEvents).toContainEqual(\n      expect.objectContaining({\n        name: 'support/issue.progress',\n        data: expect.objectContaining({\n          tenantId: 'egghead',\n          conversationId: 'conv_123',\n        }),\n      })\n    )\n  })\n})\n```\n\n## Testing Step Functions\n\n```typescript\n// src/inngest/migration/migrate-user.test.ts\nimport { describe, it, expect } from 'vitest'\nimport { migrateUser } from './migrate-user'\nimport { createTestContext } from '@/test/utils/inngest'\n\ndescribe('migrateUser', () =\u003e {\n  it('executes steps in correct order', async () =\u003e {\n    const { runFunction, getStepOrder } = createTestContext()\n    \n    const event = {\n      name: 'migration/user.migrate',\n      data: { railsUserId: 123 },\n    }\n    \n    await runFunction(migrateUser, event)\n    \n    const stepOrder = getStepOrder()\n    expect(stepOrder).toEqual([\n      'fetch-rails-user',\n      'transform-user',\n      'create-cb-user',\n      'migrate-entitlements',\n      'migrate-progress',\n      'verify-migration',\n    ])\n  })\n  \n  it('handles step failure with retry', async () =\u003e {\n    const { runFunction, failStep, getRetryCount } = createTestContext()\n    \n    // Fail the first attempt\n    failStep('create-cb-user', new Error('DB connection failed'))\n    \n    const event = {\n      name: 'migration/user.migrate',\n      data: { railsUserId: 123 },\n    }\n    \n    await runFunction(migrateUser, event)\n    \n    expect(getRetryCount('create-cb-user')).toBe(1)\n  })\n})\n```\n\n## Integration Testing with Inngest Dev Server\n\n```typescript\n// src/inngest/support/full-flow.integration.ts\nimport { describe, it, expect, beforeAll, afterAll } from 'vitest'\nimport { Inngest } from 'inngest'\nimport { serve } from 'inngest/next'\n\ndescribe('Support Flow (integration)', () =\u003e {\n  let inngestDevServer: any\n  \n  beforeAll(async () =\u003e {\n    // Start Inngest dev server\n    inngestDevServer = await startInngestDev()\n  })\n  \n  afterAll(async () =\u003e {\n    await inngestDevServer.stop()\n  })\n  \n  it('full flow: webhook â†’ classify â†’ resolve â†’ reply', async () =\u003e {\n    // Send event\n    await inngest.send({\n      name: 'support/conversation.received',\n      data: {\n        tenantId: 'egghead',\n        conversationId: 'conv_test_123',\n        email: 'test@example.com',\n        subject: 'Password reset',\n        body: 'I forgot my password',\n      },\n    })\n    \n    // Wait for function chain to complete\n    await waitForInngestRun('classify-support-issue', 'conv_test_123')\n    await waitForInngestRun('resolve-auth-issue', 'conv_test_123')\n    \n    // Verify final state\n    const conversation = await redis.get('egghead:conv:conv_test_123')\n    expect(conversation.status).toBe('resolved')\n    expect(conversation.resolutionAttempts).toHaveLength(1)\n  })\n})\n```\n\n## Mocking External Services in Inngest\n\n```typescript\n// test/utils/inngest-mocks.ts\nimport { vi } from 'vitest'\n\nexport function mockInngestDependencies() {\n  // Mock OpenAI\n  vi.mock('@/lib/openai', () =\u003e ({\n    embed: vi.fn().mockResolvedValue(new Array(1536).fill(0)),\n    classify: vi.fn().mockResolvedValue({ category: 'AUTH' }),\n  }))\n  \n  // Mock Front API\n  vi.mock('@/lib/front', () =\u003e ({\n    sendReply: vi.fn().mockResolvedValue({ id: 'msg_123' }),\n    addTag: vi.fn().mockResolvedValue({}),\n  }))\n  \n  // Mock Stripe\n  vi.mock('@/lib/stripe', () =\u003e ({\n    getSubscription: vi.fn().mockResolvedValue({ status: 'active' }),\n  }))\n}\n```","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T10:06:35.41479-08:00","updated_at":"2025-12-11T10:06:35.41479-08:00","dependencies":[{"issue_id":"migrate-egghead-6y2.5","depends_on_id":"migrate-egghead-6y2","type":"parent-child","created_at":"2025-12-11T10:06:35.415349-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6y2.6","title":"Create test data factories and fixtures","description":"Create reusable test data factories and fixtures.\n\n## Factory Pattern with @faker-js/faker\n\n```typescript\n// test/factories/user.ts\nimport { faker } from '@faker-js/faker'\nimport { User } from '@/db/schema'\n\ninterface UserOverrides extends Partial\u003cUser\u003e {}\n\nexport function createUser(overrides: UserOverrides = {}): User {\n  return {\n    id: faker.string.uuid(),\n    email: faker.internet.email(),\n    name: faker.person.fullName(),\n    image: faker.image.avatar(),\n    emailVerified: faker.date.past(),\n    createdAt: faker.date.past(),\n    updatedAt: new Date(),\n    ...overrides,\n  }\n}\n\n// Specific user types\nexport function createProUser(overrides: UserOverrides = {}): User {\n  return createUser({\n    ...overrides,\n  })\n}\n\nexport function createTeamAdmin(overrides: UserOverrides = {}): User {\n  return createUser({\n    role: 'admin',\n    ...overrides,\n  })\n}\n```\n\n```typescript\n// test/factories/subscription.ts\nimport { faker } from '@faker-js/faker'\nimport { Subscription } from '@/db/schema'\n\nexport function createSubscription(overrides: Partial\u003cSubscription\u003e = {}): Subscription {\n  const now = new Date()\n  const periodEnd = new Date(now.getTime() + 30 * 24 * 60 * 60 * 1000)\n  \n  return {\n    id: faker.string.uuid(),\n    stripeSubscriptionId: `sub_${faker.string.alphanumeric(24)}`,\n    stripeCustomerId: `cus_${faker.string.alphanumeric(24)}`,\n    status: 'active',\n    priceId: 'price_pro_monthly',\n    currentPeriodStart: now,\n    currentPeriodEnd: periodEnd,\n    cancelAtPeriodEnd: false,\n    createdAt: now,\n    updatedAt: now,\n    ...overrides,\n  }\n}\n\nexport function createCanceledSubscription(overrides: Partial\u003cSubscription\u003e = {}) {\n  return createSubscription({\n    status: 'canceled',\n    cancelAtPeriodEnd: true,\n    ...overrides,\n  })\n}\n\nexport function createPastDueSubscription(overrides: Partial\u003cSubscription\u003e = {}) {\n  return createSubscription({\n    status: 'past_due',\n    ...overrides,\n  })\n}\n```\n\n## Fixture Files (Static Test Data)\n\n```typescript\n// test/fixtures/stripe-events/checkout.session.completed.json\n{\n  \"id\": \"evt_test_checkout_completed\",\n  \"type\": \"checkout.session.completed\",\n  \"data\": {\n    \"object\": {\n      \"id\": \"cs_test_xxx\",\n      \"customer\": \"cus_test_xxx\",\n      \"subscription\": \"sub_test_xxx\",\n      \"mode\": \"subscription\",\n      \"payment_status\": \"paid\",\n      \"metadata\": {\n        \"userId\": \"user_123\"\n      }\n    }\n  }\n}\n```\n\n```typescript\n// test/fixtures/index.ts\nimport checkoutCompleted from './stripe-events/checkout.session.completed.json'\nimport subscriptionCreated from './stripe-events/customer.subscription.created.json'\n// ... more\n\nexport const stripeFixtures = {\n  checkoutCompleted,\n  subscriptionCreated,\n  // ...\n}\n\n// Load fixture with type safety\nexport function loadStripeFixture\u003cT extends keyof typeof stripeFixtures\u003e(\n  name: T\n): typeof stripeFixtures[T] {\n  return stripeFixtures[name]\n}\n```\n\n## Database Seeders\n\n```typescript\n// test/seeds/index.ts\nimport { DrizzleDB } from '@/db'\nimport { createUser, createProUser } from '../factories/user'\nimport { createSubscription } from '../factories/subscription'\n\nexport async function seedTestUsers(db: DrizzleDB) {\n  const users = [\n    createUser({ id: 'free_user', email: 'free@test.com' }),\n    createProUser({ id: 'pro_user', email: 'pro@test.com' }),\n    createUser({ id: 'team_admin', email: 'admin@test.com' }),\n  ]\n  \n  await db.insert(usersTable).values(users)\n  return users\n}\n\nexport async function seedTestSubscriptions(db: DrizzleDB) {\n  const subscriptions = [\n    createSubscription({ userId: 'pro_user' }),\n  ]\n  \n  await db.insert(subscriptionsTable).values(subscriptions)\n  return subscriptions\n}\n\nexport async function seedFullTestData(db: DrizzleDB) {\n  const users = await seedTestUsers(db)\n  const subscriptions = await seedTestSubscriptions(db)\n  // ... more\n  \n  return { users, subscriptions }\n}\n```\n\n## Factory Sequences (for unique values)\n\n```typescript\n// test/factories/sequences.ts\nlet userSequence = 0\nlet subscriptionSequence = 0\n\nexport function nextUserId() {\n  return `user_${++userSequence}`\n}\n\nexport function nextSubscriptionId() {\n  return `sub_${++subscriptionSequence}`\n}\n\nexport function resetSequences() {\n  userSequence = 0\n  subscriptionSequence = 0\n}\n```\n\n## Builder Pattern for Complex Objects\n\n```typescript\n// test/factories/builders/user-with-subscription.ts\nexport class TestUserBuilder {\n  private user: Partial\u003cUser\u003e = {}\n  private subscription: Partial\u003cSubscription\u003e | null = null\n  private entitlements: Partial\u003cEntitlement\u003e[] = []\n  \n  withEmail(email: string) {\n    this.user.email = email\n    return this\n  }\n  \n  withProSubscription() {\n    this.subscription = createSubscription()\n    this.entitlements.push({ type: 'pro', source: 'subscription' })\n    return this\n  }\n  \n  withTeamAccess(orgId: string) {\n    this.entitlements.push({ type: 'pro', source: 'team', organizationId: orgId })\n    return this\n  }\n  \n  async build(db: DrizzleDB) {\n    const user = createUser(this.user)\n    await db.insert(usersTable).values(user)\n    \n    if (this.subscription) {\n      await db.insert(subscriptionsTable).values({\n        ...this.subscription,\n        userId: user.id,\n      })\n    }\n    \n    for (const entitlement of this.entitlements) {\n      await db.insert(entitlementsTable).values({\n        ...createEntitlement(entitlement),\n        userId: user.id,\n      })\n    }\n    \n    return user\n  }\n}\n\n// Usage\nconst user = await new TestUserBuilder()\n  .withEmail('test@example.com')\n  .withProSubscription()\n  .build(db)\n```","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T10:06:55.87349-08:00","updated_at":"2025-12-11T10:06:55.87349-08:00","dependencies":[{"issue_id":"migrate-egghead-6y2.6","depends_on_id":"migrate-egghead-6y2","type":"parent-child","created_at":"2025-12-11T10:06:55.87391-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-6y2.7","title":"Add CI pipeline with test gates","description":"Set up CI/CD pipeline that's fast, reliable, and doesn't slow us down.\n\n## Philosophy: Fast Feedback, Real Tests\n\nCI should catch real bugs without being a bottleneck. Every minute of CI time is a minute of developer waiting.\n\n## Pipeline Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                         PUSH TO BRANCH                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Parallel (total ~3min):                                        â”‚\nâ”‚  â”œâ”€ Lint + Typecheck (30s)                                      â”‚\nâ”‚  â”œâ”€ Unit tests (1-2min)                                         â”‚\nâ”‚  â””â”€ Integration tests (2-3min)  â† Real DB, real Stripe          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â”‚\n                              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                         PR TO MAIN                              â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Above + (runs after unit/integration pass):                    â”‚\nâ”‚  â”œâ”€ E2E critical paths (5min)  â† Chromium only                  â”‚\nâ”‚  â””â”€ Coverage check (80% gate)                                   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â”‚\n                              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                        MERGE TO MAIN                            â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  â”œâ”€ Full E2E (all browsers)                                     â”‚\nâ”‚  â”œâ”€ Deploy to Vercel preview                                    â”‚\nâ”‚  â””â”€ Smoke tests against preview                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## GitHub Actions Workflow\n\n```yaml\n# .github/workflows/ci.yml\nname: CI\n\non:\n  push:\n    branches: ['**']\n  pull_request:\n    branches: [main]\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  # ============================================\n  # FAST CHECKS - Run on every push\n  # ============================================\n  \n  lint-and-types:\n    runs-on: ubuntu-latest\n    timeout-minutes: 5\n    steps:\n      - uses: actions/checkout@v4\n      - uses: pnpm/action-setup@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n      - run: pnpm lint\n      - run: pnpm typecheck\n\n  unit:\n    runs-on: ubuntu-latest\n    timeout-minutes: 5\n    steps:\n      - uses: actions/checkout@v4\n      - uses: pnpm/action-setup@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n      - run: pnpm test:unit --coverage\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage\n          path: coverage/\n\n  integration:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    services:\n      mysql:\n        image: mysql:8.0\n        env:\n          MYSQL_ROOT_PASSWORD: test\n          MYSQL_DATABASE: test\n        ports:\n          - 3306:3306\n        options: \u003e-\n          --health-cmd=\"mysqladmin ping\"\n          --health-interval=10s\n          --health-timeout=5s\n          --health-retries=3\n      redis:\n        image: redis:7\n        ports:\n          - 6379:6379\n    steps:\n      - uses: actions/checkout@v4\n      - uses: pnpm/action-setup@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n      - run: pnpm db:migrate\n        env:\n          DATABASE_URL: mysql://root:test@localhost:3306/test\n      - run: pnpm test:integration\n        env:\n          DATABASE_URL: mysql://root:test@localhost:3306/test\n          REDIS_URL: redis://localhost:6379\n          STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY_TEST }}\n\n  # ============================================\n  # PR CHECKS - Only on PRs to main\n  # ============================================\n  \n  e2e:\n    if: github.event_name == 'pull_request'\n    needs: [lint-and-types, unit]  # Don't waste time if basics fail\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n    steps:\n      - uses: actions/checkout@v4\n      - uses: pnpm/action-setup@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n      - run: pnpm exec playwright install chromium --with-deps\n      - run: pnpm build\n      - run: pnpm test:e2e --project=chromium\n        env:\n          DATABASE_URL: ${{ secrets.TEST_DATABASE_URL }}\n      - uses: actions/upload-artifact@v4\n        if: failure()\n        with:\n          name: playwright-report\n          path: playwright-report/\n          retention-days: 7\n\n  coverage-gate:\n    if: github.event_name == 'pull_request'\n    needs: [unit]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: coverage\n      - name: Check coverage threshold\n        run: |\n          COVERAGE=$(jq '.total.lines.pct' coverage/coverage-summary.json)\n          echo \"Coverage: $COVERAGE%\"\n          if (( $(echo \"$COVERAGE \u003c 80\" | bc -l) )); then\n            echo \"::error::Coverage $COVERAGE% is below 80% threshold\"\n            exit 1\n          fi\n\n  # ============================================\n  # MERGE CHECKS - Only on main\n  # ============================================\n  \n  e2e-full:\n    if: github.ref == 'refs/heads/main'\n    needs: [lint-and-types, unit, integration]\n    runs-on: ubuntu-latest\n    timeout-minutes: 20\n    strategy:\n      matrix:\n        browser: [chromium, firefox, webkit]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: pnpm/action-setup@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n      - run: pnpm exec playwright install ${{ matrix.browser }} --with-deps\n      - run: pnpm build\n      - run: pnpm test:e2e --project=${{ matrix.browser }}\n```\n\n## Speed Optimizations\n\n### 1. Aggressive Caching\n\n```yaml\n- uses: actions/cache@v4\n  with:\n    path: |\n      ~/.pnpm-store\n      node_modules/.cache\n      .next/cache\n    key: ${{ runner.os }}-pnpm-${{ hashFiles('pnpm-lock.yaml') }}\n    restore-keys: |\n      ${{ runner.os }}-pnpm-\n```\n\n### 2. Parallel Everything\n\n```yaml\n# Run lint, unit, integration in parallel\n# E2E waits for fast checks to pass first\n```\n\n### 3. Skip Unchanged\n\n```yaml\n# Only run tests for changed packages in monorepo\n- uses: dorny/paths-filter@v2\n  id: changes\n  with:\n    filters: |\n      app:\n        - 'apps/egghead/**'\n      packages:\n        - 'packages/**'\n\n- run: pnpm test:unit\n  if: steps.changes.outputs.app == 'true'\n```\n\n### 4. Fail Fast\n\n```yaml\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true  # Kill old runs when new push comes\n```\n\n## Branch Protection\n\n```yaml\n# Required status checks before merge\nrequired_status_checks:\n  strict: true\n  contexts:\n    - lint-and-types\n    - unit\n    - integration\n    - e2e\n    - coverage-gate\n```\n\n## Notifications\n\n```yaml\nnotify:\n  if: failure() \u0026\u0026 github.ref == 'refs/heads/main'\n  needs: [e2e-full]\n  runs-on: ubuntu-latest\n  steps:\n    - uses: slackapi/slack-github-action@v1\n      with:\n        payload: |\n          {\n            \"text\": \"ğŸ”´ Main branch CI failed\",\n            \"blocks\": [{\n              \"type\": \"section\",\n              \"text\": {\n                \"type\": \"mrkdwn\",\n                \"text\": \"*CI Failed on main*\\n\u003c${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Run\u003e\"\n              }\n            }]\n          }\n      env:\n        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}\n```\n\n## Local Pre-commit (Optional)\n\n```bash\n# .husky/pre-commit\n#!/bin/sh\n# Only run affected tests - fast feedback\npnpm vitest --changed HEAD~1 --run\n```\n\n## What We're NOT Doing\n\n- âŒ Running all tests on every push (too slow)\n- âŒ Multiple browser E2E on PRs (chromium only, full suite on main)\n- âŒ Blocking on flaky tests (fix or delete immediately)\n- âŒ Complex matrix builds (keep it simple)\n- âŒ Separate staging deploys (Vercel previews are enough)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T10:07:16.088201-08:00","updated_at":"2025-12-11T10:09:01.464733-08:00","dependencies":[{"issue_id":"migrate-egghead-6y2.7","depends_on_id":"migrate-egghead-6y2","type":"parent-child","created_at":"2025-12-11T10:07:16.088614-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-axl","title":"Phase 6: Cutover + Final E2E Validation","description":"Execute the cutover: dual-write webhooks, shadow mode (7+ days), flip primary, auth cutover, DNS switch. Each step has E2E validation and human checkpoints. Gate: 7 days stable post-DNS, final authorization to kill Rails. RAILS IS DEAD.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:29:58.541849-08:00","updated_at":"2025-12-11T09:29:58.541849-08:00"}
{"id":"migrate-egghead-axl.1","title":"Deploy dual-write webhook configuration (Rails primary, CB shadow)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:58.573993-08:00","updated_at":"2025-12-11T09:29:58.573993-08:00","dependencies":[{"issue_id":"migrate-egghead-axl.1","depends_on_id":"migrate-egghead-axl","type":"parent-child","created_at":"2025-12-11T09:29:58.5743-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-axl.10","title":"[HUMAN] Post-cutover monitoring + KILL RAILS authorization","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:58.86953-08:00","updated_at":"2025-12-11T09:29:58.86953-08:00","dependencies":[{"issue_id":"migrate-egghead-axl.10","depends_on_id":"migrate-egghead-axl","type":"parent-child","created_at":"2025-12-11T09:29:58.869983-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-axl.2","title":"Build shadow traffic comparison tool","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:58.605231-08:00","updated_at":"2025-12-11T09:29:58.605231-08:00","dependencies":[{"issue_id":"migrate-egghead-axl.2","depends_on_id":"migrate-egghead-axl","type":"parent-child","created_at":"2025-12-11T09:29:58.605531-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-axl.3","title":"E2E: Run full suite against shadow mode","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:58.636924-08:00","updated_at":"2025-12-11T09:29:58.636924-08:00","dependencies":[{"issue_id":"migrate-egghead-axl.3","depends_on_id":"migrate-egghead-axl","type":"parent-child","created_at":"2025-12-11T09:29:58.637281-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-axl.4","title":"[HUMAN] Shadow mode review (7+ days, \u003c0.1% divergence)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:58.669454-08:00","updated_at":"2025-12-11T09:29:58.669454-08:00","dependencies":[{"issue_id":"migrate-egghead-axl.4","depends_on_id":"migrate-egghead-axl","type":"parent-child","created_at":"2025-12-11T09:29:58.669763-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-axl.5","title":"Execute flip to Coursebuilder primary","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:58.703073-08:00","updated_at":"2025-12-11T09:29:58.703073-08:00","dependencies":[{"issue_id":"migrate-egghead-axl.5","depends_on_id":"migrate-egghead-axl","type":"parent-child","created_at":"2025-12-11T09:29:58.703383-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-axl.6","title":"Auth cutover + password reset campaign","description":"Auth cutover + password reset campaign\n\nDETAILED RUNBOOK:\n\n1. PRE-CUTOVER (T-7 days):\n   - Identify OAuth-only users (no password set)\n   - Send \"set your password\" email campaign\n   - Test password reset flow end-to-end\n\n2. PRE-CUTOVER (T-48 hours):\n   - Send password reset reminder to all users\n   - Notify support team of upcoming cutover\n   - Prepare locked-out user support playbook\n\n3. CUTOVER DAY:\n   - Invalidate all Rails sessions\n   - Switch auth to Coursebuilder NextAuth\n   - Monitor login success rate dashboard\n   - Support team on standby\n\n4. POST-CUTOVER:\n   - OAuth re-linking flow for GitHub/Discord\n   - Handle locked-out user tickets\n   - Monitor for auth-related errors\n\nSee epic migrate-egghead-04y for detailed subtasks.","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:58.735979-08:00","updated_at":"2025-12-11T09:54:15.243872-08:00","dependencies":[{"issue_id":"migrate-egghead-axl.6","depends_on_id":"migrate-egghead-axl","type":"parent-child","created_at":"2025-12-11T09:29:58.736299-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-axl.7","title":"E2E: Post-flip full regression suite","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:58.769067-08:00","updated_at":"2025-12-11T09:29:58.769067-08:00","dependencies":[{"issue_id":"migrate-egghead-axl.7","depends_on_id":"migrate-egghead-axl","type":"parent-child","created_at":"2025-12-11T09:29:58.769368-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-axl.8","title":"[HUMAN] DNS cutover authorization (24h+ stable)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:58.802579-08:00","updated_at":"2025-12-11T09:29:58.802579-08:00","dependencies":[{"issue_id":"migrate-egghead-axl.8","depends_on_id":"migrate-egghead-axl","type":"parent-child","created_at":"2025-12-11T09:29:58.802902-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-axl.9","title":"Execute DNS cutover (keep Rails read-only 7 days)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:58.834774-08:00","updated_at":"2025-12-11T09:29:58.834774-08:00","dependencies":[{"issue_id":"migrate-egghead-axl.9","depends_on_id":"migrate-egghead-axl","type":"parent-child","created_at":"2025-12-11T09:29:58.835099-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-dxh","title":"Team Features (Not Deferred)","description":"Team features are NOT deferred. 266 teams with 1,619 seats represent significant revenue.\n\nMinimum viable team features:\n- Team dashboard (read members, see seats)\n- Invite flow (send invite, accept invite)\n- Seat management (add/remove members)\n- Team billing (view invoices, manage subscription)\n\nDefer to post-launch:\n- Ownership transfer\n- SAML SSO (~15 enterprise accounts)","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:54:04.964051-08:00","updated_at":"2025-12-11T09:54:04.964051-08:00"}
{"id":"migrate-egghead-dxh.1","title":"Build team dashboard page (view members, seats used)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:54:04.998004-08:00","updated_at":"2025-12-11T09:54:04.998004-08:00","dependencies":[{"issue_id":"migrate-egghead-dxh.1","depends_on_id":"migrate-egghead-dxh","type":"parent-child","created_at":"2025-12-11T09:54:04.998423-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-dxh.2","title":"Build team invite flow (send invite email)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:54:05.029783-08:00","updated_at":"2025-12-11T09:54:05.029783-08:00","dependencies":[{"issue_id":"migrate-egghead-dxh.2","depends_on_id":"migrate-egghead-dxh","type":"parent-child","created_at":"2025-12-11T09:54:05.030132-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-dxh.3","title":"Build invite acceptance flow (token-based)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:54:05.062114-08:00","updated_at":"2025-12-11T09:54:05.062114-08:00","dependencies":[{"issue_id":"migrate-egghead-dxh.3","depends_on_id":"migrate-egghead-dxh","type":"parent-child","created_at":"2025-12-11T09:54:05.062465-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-dxh.4","title":"Build seat management (add/remove team members)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:54:05.094677-08:00","updated_at":"2025-12-11T09:54:05.094677-08:00","dependencies":[{"issue_id":"migrate-egghead-dxh.4","depends_on_id":"migrate-egghead-dxh","type":"parent-child","created_at":"2025-12-11T09:54:05.095005-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-dxh.5","title":"Build team billing page (invoices, manage subscription)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:54:05.127039-08:00","updated_at":"2025-12-11T09:54:05.127039-08:00","dependencies":[{"issue_id":"migrate-egghead-dxh.5","depends_on_id":"migrate-egghead-dxh","type":"parent-child","created_at":"2025-12-11T09:54:05.127372-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-dxh.6","title":"Migrate team data from Rails (266 teams, account_users)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:54:05.159934-08:00","updated_at":"2025-12-11T09:54:05.159934-08:00","dependencies":[{"issue_id":"migrate-egghead-dxh.6","depends_on_id":"migrate-egghead-dxh","type":"parent-child","created_at":"2025-12-11T09:54:05.160265-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-h14","title":"Migration gap analysis and README enhancement","description":"Find holes in the egghead migration plan, leverage pdf-brain knowledge, create bulletproof step-by-step README","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:02:03.607541-08:00","updated_at":"2025-12-11T09:06:06.22885-08:00","closed_at":"2025-12-11T09:06:06.22885-08:00"}
{"id":"migrate-egghead-h14.1","title":"Search pdf-brain for data migration patterns","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T09:02:03.641222-08:00","updated_at":"2025-12-11T09:04:34.081748-08:00","closed_at":"2025-12-11T09:04:34.081748-08:00","dependencies":[{"issue_id":"migrate-egghead-h14.1","depends_on_id":"migrate-egghead-h14","type":"parent-child","created_at":"2025-12-11T09:02:03.641579-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-h14.2","title":"Analyze egghead-rails for undocumented dependencies","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T09:02:03.676076-08:00","updated_at":"2025-12-11T09:04:36.001741-08:00","closed_at":"2025-12-11T09:04:36.001741-08:00","dependencies":[{"issue_id":"migrate-egghead-h14.2","depends_on_id":"migrate-egghead-h14","type":"parent-child","created_at":"2025-12-11T09:02:03.676417-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-h14.3","title":"Analyze egghead-next for undocumented features","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T09:02:03.710342-08:00","updated_at":"2025-12-11T09:04:37.20502-08:00","closed_at":"2025-12-11T09:04:37.20502-08:00","dependencies":[{"issue_id":"migrate-egghead-h14.3","depends_on_id":"migrate-egghead-h14","type":"parent-child","created_at":"2025-12-11T09:02:03.71072-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-h14.4","title":"Audit Coursebuilder readiness gaps","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T09:02:03.744146-08:00","updated_at":"2025-12-11T09:04:38.716505-08:00","closed_at":"2025-12-11T09:04:38.716505-08:00","dependencies":[{"issue_id":"migrate-egghead-h14.4","depends_on_id":"migrate-egghead-h14","type":"parent-child","created_at":"2025-12-11T09:02:03.74447-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-h14.5","title":"Synthesize findings and update README","description":"","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-11T09:02:03.776718-08:00","updated_at":"2025-12-11T09:05:58.73749-08:00","closed_at":"2025-12-11T09:05:58.73749-08:00","dependencies":[{"issue_id":"migrate-egghead-h14.5","depends_on_id":"migrate-egghead-h14","type":"parent-child","created_at":"2025-12-11T09:02:03.777066-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-ifz","title":"Customer.io Integration","description":"Port Customer.io integration from Rails to Coursebuilder. Follow the pattern from ai-hero's email-list-provider.ts using the existing ConvertKit provider as template.\n\nEvents to track:\n- subscribed (new subscription)\n- billed (renewal payment)\n- subscription removed (cancellation)\n\nUser attributes to sync:\n- is_pro (boolean)\n- Plan_Interval (month/year)\n- subscription_status","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:53:35.891099-08:00","updated_at":"2025-12-11T09:53:35.891099-08:00"}
{"id":"migrate-egghead-ifz.1","title":"Create CustomerioProvider following ConvertKit pattern","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:35.924794-08:00","updated_at":"2025-12-11T09:53:35.924794-08:00","dependencies":[{"issue_id":"migrate-egghead-ifz.1","depends_on_id":"migrate-egghead-ifz","type":"parent-child","created_at":"2025-12-11T09:53:35.925162-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-ifz.2","title":"Add Customer.io SDK to egghead app","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:35.962133-08:00","updated_at":"2025-12-11T09:53:35.962133-08:00","dependencies":[{"issue_id":"migrate-egghead-ifz.2","depends_on_id":"migrate-egghead-ifz","type":"parent-child","created_at":"2025-12-11T09:53:35.962572-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-ifz.3","title":"Implement event tracking: subscribed","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:35.996946-08:00","updated_at":"2025-12-11T09:53:35.996946-08:00","dependencies":[{"issue_id":"migrate-egghead-ifz.3","depends_on_id":"migrate-egghead-ifz","type":"parent-child","created_at":"2025-12-11T09:53:35.99732-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-ifz.4","title":"Implement event tracking: billed","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:36.036228-08:00","updated_at":"2025-12-11T09:53:36.036228-08:00","dependencies":[{"issue_id":"migrate-egghead-ifz.4","depends_on_id":"migrate-egghead-ifz","type":"parent-child","created_at":"2025-12-11T09:53:36.036624-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-ifz.5","title":"Implement event tracking: subscription removed","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:36.071917-08:00","updated_at":"2025-12-11T09:53:36.071917-08:00","dependencies":[{"issue_id":"migrate-egghead-ifz.5","depends_on_id":"migrate-egghead-ifz","type":"parent-child","created_at":"2025-12-11T09:53:36.072303-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-ifz.6","title":"Implement user attribute sync (is_pro, Plan_Interval)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:36.106746-08:00","updated_at":"2025-12-11T09:53:36.106746-08:00","dependencies":[{"issue_id":"migrate-egghead-ifz.6","depends_on_id":"migrate-egghead-ifz","type":"parent-child","created_at":"2025-12-11T09:53:36.107139-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-koh","title":"Phase 1: Data Migration Scripts + Validation","description":"Migrate all data from Rails PostgreSQL to Coursebuilder PlanetScale: 699K users, 94K orgs, 3,335 subscriptions, 3M progress records, 420 courses, 5,132 lessons. All scripts support --dry-run, are idempotent, and resumable. Gate: Reconciliation passes + E2E tests green.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:28:54.927552-08:00","updated_at":"2025-12-11T09:28:54.927552-08:00"}
{"id":"migrate-egghead-koh.1","title":"User migration script (699K users) with dry-run","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:54.960872-08:00","updated_at":"2025-12-11T09:28:54.960872-08:00","dependencies":[{"issue_id":"migrate-egghead-koh.1","depends_on_id":"migrate-egghead-koh","type":"parent-child","created_at":"2025-12-11T09:28:54.96124-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-koh.10","title":"[HUMAN] Validate data migration with reconciliation + E2E green","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:55.237502-08:00","updated_at":"2025-12-11T09:28:55.237502-08:00","dependencies":[{"issue_id":"migrate-egghead-koh.10","depends_on_id":"migrate-egghead-koh","type":"parent-child","created_at":"2025-12-11T09:28:55.237842-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-koh.2","title":"Organization migration script (94K accounts)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:54.993648-08:00","updated_at":"2025-12-11T09:28:54.993648-08:00","dependencies":[{"issue_id":"migrate-egghead-koh.2","depends_on_id":"migrate-egghead-koh","type":"parent-child","created_at":"2025-12-11T09:28:54.993973-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-koh.3","title":"OrganizationMembership + MerchantCustomer migration","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:55.026168-08:00","updated_at":"2025-12-11T09:28:55.026168-08:00","dependencies":[{"issue_id":"migrate-egghead-koh.3","depends_on_id":"migrate-egghead-koh","type":"parent-child","created_at":"2025-12-11T09:28:55.026514-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-koh.4","title":"Subscription + MerchantSubscription migration (3,335 active)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:55.057157-08:00","updated_at":"2025-12-11T09:28:55.057157-08:00","dependencies":[{"issue_id":"migrate-egghead-koh.4","depends_on_id":"migrate-egghead-koh","type":"parent-child","created_at":"2025-12-11T09:28:55.057469-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-koh.5","title":"Entitlement migration script (pro access grants)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:55.086039-08:00","updated_at":"2025-12-11T09:28:55.086039-08:00","dependencies":[{"issue_id":"migrate-egghead-koh.5","depends_on_id":"migrate-egghead-koh","type":"parent-child","created_at":"2025-12-11T09:28:55.086339-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-koh.6","title":"Content migration (420 courses, 5,132 lessons, 627 tags)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:55.115195-08:00","updated_at":"2025-12-11T09:28:55.115195-08:00","dependencies":[{"issue_id":"migrate-egghead-koh.6","depends_on_id":"migrate-egghead-koh","type":"parent-child","created_at":"2025-12-11T09:28:55.115503-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-koh.7","title":"Instructor migration (134 instructors)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:28:55.143737-08:00","updated_at":"2025-12-11T09:28:55.143737-08:00","dependencies":[{"issue_id":"migrate-egghead-koh.7","depends_on_id":"migrate-egghead-koh","type":"parent-child","created_at":"2025-12-11T09:28:55.144036-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-koh.8","title":"Progress migration (3M records, batch processing)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:28:55.174106-08:00","updated_at":"2025-12-11T09:28:55.174106-08:00","dependencies":[{"issue_id":"migrate-egghead-koh.8","depends_on_id":"migrate-egghead-koh","type":"parent-child","created_at":"2025-12-11T09:28:55.174434-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-koh.9","title":"E2E: Verify migrated user auth + content renders + entitlements gate","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:28:55.205751-08:00","updated_at":"2025-12-11T09:28:55.205751-08:00","dependencies":[{"issue_id":"migrate-egghead-koh.9","depends_on_id":"migrate-egghead-koh","type":"parent-child","created_at":"2025-12-11T09:28:55.206065-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-mnn","title":"Sanity Elimination - Single Database Migration","description":"Eliminate Sanity CMS dependency. All content moves to PlanetScale ContentResource tables. egghead becomes a SINGLE DATABASE application.\n\nCurrent state: ~100 Sanity references in egghead app (lessons, courses, collaborators, software libraries)\nTarget state: All content in ContentResource with fields JSON\n\nNote: 193 missing videos will redirect to /gone page (deprecated content)","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:53:02.492794-08:00","updated_at":"2025-12-11T09:53:02.492794-08:00"}
{"id":"migrate-egghead-mnn.1","title":"Audit all Sanity content types and map to ContentResource fields","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:02.524059-08:00","updated_at":"2025-12-11T09:53:02.524059-08:00","dependencies":[{"issue_id":"migrate-egghead-mnn.1","depends_on_id":"migrate-egghead-mnn","type":"parent-child","created_at":"2025-12-11T09:53:02.524419-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-mnn.2","title":"Build ContentResource migration script for Sanity lessons","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:02.557175-08:00","updated_at":"2025-12-11T09:53:02.557175-08:00","dependencies":[{"issue_id":"migrate-egghead-mnn.2","depends_on_id":"migrate-egghead-mnn","type":"parent-child","created_at":"2025-12-11T09:53:02.557499-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-mnn.3","title":"Build ContentResource migration script for Sanity courses","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:02.590149-08:00","updated_at":"2025-12-11T09:53:02.590149-08:00","dependencies":[{"issue_id":"migrate-egghead-mnn.3","depends_on_id":"migrate-egghead-mnn","type":"parent-child","created_at":"2025-12-11T09:53:02.590464-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-mnn.4","title":"Migrate collaborators/instructors from Sanity to User table","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:02.623882-08:00","updated_at":"2025-12-11T09:53:02.623882-08:00","dependencies":[{"issue_id":"migrate-egghead-mnn.4","depends_on_id":"migrate-egghead-mnn","type":"parent-child","created_at":"2025-12-11T09:53:02.62422-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-mnn.5","title":"Remove all Sanity write client usage (100+ references)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:02.657946-08:00","updated_at":"2025-12-11T09:53:02.657946-08:00","dependencies":[{"issue_id":"migrate-egghead-mnn.5","depends_on_id":"migrate-egghead-mnn","type":"parent-child","created_at":"2025-12-11T09:53:02.658288-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-mnn.6","title":"Update Inngest functions to write to ContentResource instead of Sanity","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:02.690762-08:00","updated_at":"2025-12-11T09:53:02.690762-08:00","dependencies":[{"issue_id":"migrate-egghead-mnn.6","depends_on_id":"migrate-egghead-mnn","type":"parent-child","created_at":"2025-12-11T09:53:02.691097-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-mnn.7","title":"Build /gone page for deprecated content (193 missing videos)","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:53:02.726939-08:00","updated_at":"2025-12-11T09:53:02.726939-08:00","dependencies":[{"issue_id":"migrate-egghead-mnn.7","depends_on_id":"migrate-egghead-mnn","type":"parent-child","created_at":"2025-12-11T09:53:02.727271-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-mnn.8","title":"Remove Sanity dependencies from package.json","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:53:02.760666-08:00","updated_at":"2025-12-11T09:53:02.760666-08:00","dependencies":[{"issue_id":"migrate-egghead-mnn.8","depends_on_id":"migrate-egghead-mnn","type":"parent-child","created_at":"2025-12-11T09:53:02.761004-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-mnn.9","title":"Document Sanity touchpoints before elimination","description":"Before removing ~100 Sanity references, document the major touchpoints and data flows.\n\n**Areas to document:**\n1. Content types in Sanity (lessons, courses, collaborators, software libraries)\n2. How content is fetched (GROQ queries, client setup)\n3. Studio configuration (`egghead-next/studio/`)\n4. Image/asset handling\n5. Any webhooks or real-time subscriptions\n\n**Output:** \n- List of all Sanity schema types\n- Mapping to ContentResource equivalents\n- Migration checklist for each content type\n- Any edge cases or special handling needed\n\n**Note:** 193 missing videos will redirect to /gone page (deprecated content).","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T10:26:51.284333-08:00","updated_at":"2025-12-11T10:26:51.284333-08:00","dependencies":[{"issue_id":"migrate-egghead-mnn.9","depends_on_id":"migrate-egghead-mnn","type":"parent-child","created_at":"2025-12-11T10:26:51.284705-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qk0","title":"Phase 4: External Integrations (Customer.io + Mailers)","description":"Build Customer.io integration (MISSING from Coursebuilder entirely) and migrate 17 transactional mailers to Resend/Postmark. Customer.io is critical for email automation. Gate: Customer.io events fire correctly, magic link email flow works E2E.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:29:31.449988-08:00","updated_at":"2025-12-11T09:29:31.449988-08:00"}
{"id":"migrate-egghead-qk0.1","title":"Build Customer.io API client (track/identify) - MISSING from CB","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:31.484601-08:00","updated_at":"2025-12-11T09:29:31.484601-08:00","dependencies":[{"issue_id":"migrate-egghead-qk0.1","depends_on_id":"migrate-egghead-qk0","type":"parent-child","created_at":"2025-12-11T09:29:31.484935-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qk0.2","title":"Customer.io Inngest handlers for subscription events","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:31.516808-08:00","updated_at":"2025-12-11T09:29:31.516808-08:00","dependencies":[{"issue_id":"migrate-egghead-qk0.2","depends_on_id":"migrate-egghead-qk0","type":"parent-child","created_at":"2025-12-11T09:29:31.517136-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qk0.3","title":"Migrate MagicSignInMailer to Resend","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:31.547158-08:00","updated_at":"2025-12-11T09:29:31.547158-08:00","dependencies":[{"issue_id":"migrate-egghead-qk0.3","depends_on_id":"migrate-egghead-qk0","type":"parent-child","created_at":"2025-12-11T09:29:31.547473-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qk0.4","title":"Migrate RenewalMailer + WelcomeMailer to Resend","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:29:31.576866-08:00","updated_at":"2025-12-11T09:29:31.576866-08:00","dependencies":[{"issue_id":"migrate-egghead-qk0.4","depends_on_id":"migrate-egghead-qk0","type":"parent-child","created_at":"2025-12-11T09:29:31.577181-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qk0.5","title":"Migrate remaining transactional mailers (17 total)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:29:31.608944-08:00","updated_at":"2025-12-11T09:29:31.608944-08:00","dependencies":[{"issue_id":"migrate-egghead-qk0.5","depends_on_id":"migrate-egghead-qk0","type":"parent-child","created_at":"2025-12-11T09:29:31.609281-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qk0.6","title":"E2E: Test magic link email flow end-to-end","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:31.641619-08:00","updated_at":"2025-12-11T09:29:31.641619-08:00","dependencies":[{"issue_id":"migrate-egghead-qk0.6","depends_on_id":"migrate-egghead-qk0","type":"parent-child","created_at":"2025-12-11T09:29:31.641925-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qk0.7","title":"[HUMAN] Verify Customer.io events + email delivery","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:31.674304-08:00","updated_at":"2025-12-11T09:29:31.674304-08:00","dependencies":[{"issue_id":"migrate-egghead-qk0.7","depends_on_id":"migrate-egghead-qk0","type":"parent-child","created_at":"2025-12-11T09:29:31.674624-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qqu","title":"Phase 3: Cron Jobs Migration (17 Sidekiq â†’ Inngest)","description":"Port 17 Rails Sidekiq-Cron jobs to Inngest. Critical jobs: StripeReconciler (catches missed webhooks), RefreshSitemap (SEO), GiftExpiration, LessonPublisher. Gate: Human decision on which jobs to port vs deprecate, sitemap E2E test passes.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:29:20.601044-08:00","updated_at":"2025-12-11T10:26:31.563372-08:00","closed_at":"2025-12-11T10:26:31.563372-08:00"}
{"id":"migrate-egghead-qqu.1","title":"Port StripeReconciler to Inngest (daily, catches missed webhooks)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:20.636382-08:00","updated_at":"2025-12-11T09:29:20.636382-08:00","dependencies":[{"issue_id":"migrate-egghead-qqu.1","depends_on_id":"migrate-egghead-qqu","type":"parent-child","created_at":"2025-12-11T09:29:20.636744-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qqu.2","title":"Port GiftExpirationWorker to Inngest (daily)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:29:20.672322-08:00","updated_at":"2025-12-11T09:29:20.672322-08:00","dependencies":[{"issue_id":"migrate-egghead-qqu.2","depends_on_id":"migrate-egghead-qqu","type":"parent-child","created_at":"2025-12-11T09:29:20.672698-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qqu.3","title":"Port RefreshSitemap to Inngest (4-hourly, SEO critical)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:20.705406-08:00","updated_at":"2025-12-11T09:29:20.705406-08:00","dependencies":[{"issue_id":"migrate-egghead-qqu.3","depends_on_id":"migrate-egghead-qqu","type":"parent-child","created_at":"2025-12-11T09:29:20.705759-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qqu.4","title":"Port LessonPublishWorker to Inngest (10-min scheduled publishing)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:29:20.738575-08:00","updated_at":"2025-12-11T09:29:20.738575-08:00","dependencies":[{"issue_id":"migrate-egghead-qqu.4","depends_on_id":"migrate-egghead-qqu","type":"parent-child","created_at":"2025-12-11T09:29:20.738915-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qqu.5","title":"Port SignInTokenCleaner to Inngest (1-min magic link cleanup)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:29:20.767602-08:00","updated_at":"2025-12-11T09:29:20.767602-08:00","dependencies":[{"issue_id":"migrate-egghead-qqu.5","depends_on_id":"migrate-egghead-qqu","type":"parent-child","created_at":"2025-12-11T09:29:20.767918-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qqu.6","title":"Port RenewalReminder + ranking jobs to Inngest","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:29:20.797941-08:00","updated_at":"2025-12-11T09:29:20.797941-08:00","dependencies":[{"issue_id":"migrate-egghead-qqu.6","depends_on_id":"migrate-egghead-qqu","type":"parent-child","created_at":"2025-12-11T09:29:20.798257-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qqu.7","title":"E2E: Verify sitemap generates correctly with all URLs","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:20.829602-08:00","updated_at":"2025-12-11T09:29:20.829602-08:00","dependencies":[{"issue_id":"migrate-egghead-qqu.7","depends_on_id":"migrate-egghead-qqu","type":"parent-child","created_at":"2025-12-11T09:29:20.830618-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-qqu.8","title":"[HUMAN] Decide which cron jobs to port vs deprecate (17 total)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:20.865622-08:00","updated_at":"2025-12-11T09:29:20.865622-08:00","dependencies":[{"issue_id":"migrate-egghead-qqu.8","depends_on_id":"migrate-egghead-qqu","type":"parent-child","created_at":"2025-12-11T09:29:20.866017-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52","title":"Phase 5: UI Components + Full E2E Click Matrix","description":"Build all UI components with shadcn/ui: video player (Mux, NOT xstate), lesson/course pages, search (Typesense), pricing, subscription management. Configure SEO-critical URL redirects. Gate: Full click-test matrix passes, LLM exploratory testing finds no critical issues.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:29:44.727937-08:00","updated_at":"2025-12-11T09:29:44.727937-08:00"}
{"id":"migrate-egghead-r52.1","title":"Build Mux video player component (NOT porting xstate complexity)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:44.761435-08:00","updated_at":"2025-12-11T09:29:44.761435-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.1","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T09:29:44.76176-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52.10","title":"[HUMAN] UI review + full E2E suite must be green","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:45.055971-08:00","updated_at":"2025-12-11T09:29:45.055971-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.10","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T09:29:45.056276-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52.11","title":"Build simple video player using ai-hero overlay pattern","description":"Build egghead video player using Coursebuilder's existing pattern - NOT the xstate 14-state machine from egghead-next.\n\n**Reference implementation:**\n- `course-builder/apps/ai-hero/src/app/(content)/_components/video-player-overlay.tsx`\n- `course-builder/packages/ui/hooks/use-video-player-overlay.tsx`\n\n**Pattern:**\n1. `useReducer` with 4 states: COMPLETED, BLOCKED, HIDDEN, LOADING\n2. MuxPlayer component (already in CB)\n3. Overlay components for: completion, soft block, pricing widget\n4. Progress tracking via `setProgressForResource`\n\n**DO NOT PORT:**\n- xstate lesson-machine.ts (14 states, complex)\n- Any xstate dependencies\n\n**Deliverables:**\n- Video player component for lessons\n- Completion overlay with \"next lesson\" navigation\n- Soft block overlay for non-subscribers\n- Progress tracking integration","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T10:26:46.352578-08:00","updated_at":"2025-12-11T10:26:46.352578-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.11","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T10:26:46.352982-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52.2","title":"Build lesson view page with player, transcript, navigation","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:44.794589-08:00","updated_at":"2025-12-11T09:29:44.794589-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.2","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T09:29:44.79491-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52.3","title":"Build course view page with lesson list, progress indicators","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:44.824754-08:00","updated_at":"2025-12-11T09:29:44.824754-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.3","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T09:29:44.825036-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52.4","title":"Build search UI (Typesense + InstantSearch) - /q/[[...all]] route","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:44.85552-08:00","updated_at":"2025-12-11T09:29:44.85552-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.4","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T09:29:44.855788-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52.5","title":"Build pricing page with Stripe checkout integration","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:44.888115-08:00","updated_at":"2025-12-11T09:29:44.888115-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.5","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T09:29:44.888472-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52.6","title":"Build subscription management page","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:29:44.920105-08:00","updated_at":"2025-12-11T09:29:44.920105-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.6","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T09:29:44.920412-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52.7","title":"Configure URL redirects (SEO critical) in next.config","description":"Configure URL redirects (SEO critical) in next.config\n\nCOMPREHENSIVE REDIRECT MAP:\n\n```typescript\n// Instructors (134)\n/i/:slug -\u003e /instructors/:slug (301)\n/i/:slug/rss.xml -\u003e /instructors/:slug/rss (301)\n\n// Legacy content\n/playlists/:slug -\u003e /courses/:slug (301)\n/s/:slug -\u003e /courses/:slug (301)\n/browse/:topic -\u003e /q/:topic (301)\n\n// User routes\n/user -\u003e /profile (301)\n/user/:path* -\u003e /profile/:path* (301)\n\n// Deprecated content\n/lessons/:slug (missing video) -\u003e /gone (301)\n```\n\nMUST PRESERVE (no redirect needed):\n- /lessons/:slug (5,132)\n- /courses/:slug (420)\n- /q/[...params] (massive sitemap)\n\nSee epic migrate-egghead-34t for SEO safety details.","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:44.953077-08:00","updated_at":"2025-12-11T09:54:20.808233-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.7","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T09:29:44.95352-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52.8","title":"E2E: Full click-test matrix (all critical user flows)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:29:44.987845-08:00","updated_at":"2025-12-11T09:29:44.987845-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.8","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T09:29:44.988212-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-r52.9","title":"E2E: LLM agent exploratory testing","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:29:45.022635-08:00","updated_at":"2025-12-11T09:29:45.022635-08:00","dependencies":[{"issue_id":"migrate-egghead-r52.9","depends_on_id":"migrate-egghead-r52","type":"parent-child","created_at":"2025-12-11T09:29:45.022981-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd","title":"Essential Cron Jobs (Inngest)","description":"Port ESSENTIAL Sidekiq cron jobs to Inngest. Not all 17 - just the ones that break the site.\n\nEssential jobs:\n- StripeReconciler (daily) - catches webhook failures\n- GiftExpirationWorker (daily) - gifts must expire\n- RefreshSitemap (4h) - SEO critical\n- SignInTokenCleaner (1min) - magic links pile up\n- LessonPublishWorker (10min) - scheduled content\n\nSkip for now:\n- Report workers (daily/weekly/monthly) - nice to have\n- Ranker workers - can rebuild later\n- Podcast sync - low priority","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-11T09:53:51.704278-08:00","updated_at":"2025-12-11T09:53:51.704278-08:00"}
{"id":"migrate-egghead-tkd.1","title":"Port StripeReconciler to Inngest cron (daily)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:51.739-08:00","updated_at":"2025-12-11T09:53:51.739-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.1","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T09:53:51.739353-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.10","title":"Migrate instructor data to ContentContribution","description":"Populate ContentContribution table with egghead instructor â†’ lesson mappings.\n\n**Data to migrate:**\n1. Rails `Instructor` â†’ CB `User` (may already exist from user migration)\n2. Rails `Lesson.instructor_id` â†’ `ContentContribution.userId`\n3. Rails `Lesson.id` â†’ `ContentContribution.contentId`\n4. Rails `InstructorRevenueSplit.percentage` â†’ `ContentContribution.metadata.percentageSplit`\n\n**ContributionTypes to create:**\n- `instructor` (primary, default 50% split)\n- `co-instructor` (split evenly among co-instructors)\n- `mentor` (% of mentee revenue)\n\n**Handle:**\n- Co-instructors (lesson_coinstructors table)\n- Mentor relationships (instructor_revenue_splits with credit_to_instructor_id)\n- Revenue share percentages per instructor\n\n**Script location:** `apps/egghead/src/scripts/migrate-instructor-contributions.ts`","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T10:32:47.939592-08:00","updated_at":"2025-12-11T10:32:47.939592-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.10","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T10:32:47.93993-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.11","title":"Build monthly revenue share Inngest function","description":"Inngest cron function to calculate and record monthly instructor payouts.\n\n**Trigger:** `cron: '0 0 1 * *'` (1st of month at midnight)\n\n**Steps:**\n1. Get period (previous month)\n2. Query total poolable revenue from transactions\n3. Query LessonProgress joined with ContentContribution\n4. Calculate per-instructor segments and amounts\n5. Insert ContributorRevenueSplit records\n6. Send instructor report emails (for amounts \u003e= $20)\n\n**See migrate-egghead-tkd.7 for full implementation code.**\n\n**Location:** `apps/egghead/src/inngest/functions/monthly-revenue-share.ts`\n\n**Testing:**\n- Unit test calculation logic\n- Integration test with sample data\n- Validate against historical Rails payouts","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T10:32:51.851218-08:00","updated_at":"2025-12-11T10:32:51.851218-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.11","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T10:32:51.851583-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.12","title":"Port AccountSubscriptionRenewalWorker to Inngest","description":"Daily job to send renewal reminder emails to subscribers.\n\n**Rails source:** `app/workers/account_subscription_renewal_worker.rb`\n**Schedule:** Daily at 10 minutes past midnight\n\n**Functionality:**\n- Find subscriptions expiring in X days\n- Send reminder email via Customer.io or Resend\n- Track which reminders have been sent (avoid duplicates)\n\n**Inngest function:** `apps/egghead/src/inngest/functions/subscription-renewal-reminders.ts`","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T10:32:54.936184-08:00","updated_at":"2025-12-11T10:32:54.936184-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.12","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T10:32:54.936573-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.2","title":"Port GiftExpirationWorker to Inngest cron (daily)","description":"","status":"open","priority":0,"issue_type":"task","created_at":"2025-12-11T09:53:51.777292-08:00","updated_at":"2025-12-11T09:53:51.777292-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.2","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T09:53:51.777601-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.3","title":"Port RefreshSitemap to Inngest cron (every 4h)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:51.81391-08:00","updated_at":"2025-12-11T09:53:51.81391-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.3","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T09:53:51.814239-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.4","title":"Port SignInTokenCleaner to Inngest cron (every minute)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:51.851468-08:00","updated_at":"2025-12-11T09:53:51.851468-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.4","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T09:53:51.851806-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.5","title":"Port LessonPublishWorker to Inngest cron (every 10min)","description":"","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T09:53:51.886776-08:00","updated_at":"2025-12-11T09:53:51.886776-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.5","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T09:53:51.887086-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.6","title":"Port AccountSubscriptionRenewalWorker (daily renewal reminders)","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T09:53:51.91783-08:00","updated_at":"2025-12-11T09:53:51.91783-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.6","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T09:53:51.918141-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.7","title":"Investigate royalty calculation - entitlement-based approach viable?","description":"## Investigation Complete - REVISED APPROACH\n\n### Decision: Build New System on CB Schema, Don't Port Rails\n\nThe Rails revenue share system uses Plutus double-entry accounting with 600+ lines of complex SQL. Instead of porting, we'll build a simpler system using existing Coursebuilder schemas.\n\n### Existing CB Tables We'll Use\n\n```\nContentContribution\nâ”œâ”€â”€ userId (instructor)\nâ”œâ”€â”€ contentId (lesson)\nâ”œâ”€â”€ contributionTypeId ('instructor', 'co-instructor', 'mentor')\nâ”œâ”€â”€ metadata: { percentageSplit: 0.50, ... }\nâ””â”€â”€ active\n\nContributionType\nâ”œâ”€â”€ slug: 'instructor' | 'co-instructor' | 'mentor' | 'affiliate'\nâ”œâ”€â”€ name\nâ””â”€â”€ description\n\nLessonProgress (view tracking)\nâ”œâ”€â”€ userId (viewer)\nâ”œâ”€â”€ lessonId\nâ”œâ”€â”€ completedAt\nâ””â”€â”€ createdAt\n\nEntitlement\nâ”œâ”€â”€ userId | organizationId\nâ”œâ”€â”€ entitlementType: 'pro_access' | 'contributor_revenue_share'\nâ”œâ”€â”€ sourceType: 'SUBSCRIPTION' | 'PURCHASE'\nâ”œâ”€â”€ sourceId\nâ”œâ”€â”€ metadata: { ... }\nâ””â”€â”€ expiresAt\n```\n\n### New Table Needed: ContributorRevenueSplit\n\n```typescript\n// Add to commerce schemas\nexport function getContributorRevenueSplitSchema(mysqlTable: MySqlTableFn) {\n  return mysqlTable('ContributorRevenueSplit', {\n    id: varchar('id', { length: 191 }).notNull().primaryKey(),\n    \n    // Who gets paid\n    userId: varchar('userId', { length: 191 }).notNull(),\n    \n    // What period\n    periodStart: timestamp('periodStart', { mode: 'date', fsp: 3 }).notNull(),\n    periodEnd: timestamp('periodEnd', { mode: 'date', fsp: 3 }).notNull(),\n    \n    // Calculation inputs\n    totalRevenue: decimal('totalRevenue', { precision: 10, scale: 2 }).notNull(),\n    totalSegments: int('totalSegments').notNull(),\n    userSegments: int('userSegments').notNull(),\n    percentageSplit: decimal('percentageSplit', { precision: 5, scale: 4 }).notNull(),\n    \n    // Result\n    amount: decimal('amount', { precision: 10, scale: 2 }).notNull(),\n    \n    // Status\n    status: varchar('status', { length: 50 }).default('pending').notNull(), // pending | paid | held\n    paidAt: timestamp('paidAt', { mode: 'date', fsp: 3 }),\n    \n    // Audit trail\n    metadata: json('metadata').$type\u003c{\n      lessonBreakdown?: Record\u003cstring, number\u003e, // lessonId -\u003e segments\n      calculationVersion?: string,\n      notes?: string,\n    }\u003e().default({}),\n    \n    createdAt: timestamp('createdAt', { mode: 'date', fsp: 3 }).defaultNow(),\n    updatedAt: timestamp('updatedAt', { mode: 'date', fsp: 3 }).defaultNow(),\n  }, (table) =\u003e ({\n    userIdIdx: index('userId_idx').on(table.userId),\n    periodIdx: index('period_idx').on(table.periodStart, table.periodEnd),\n    statusIdx: index('status_idx').on(table.status),\n  }))\n}\n```\n\n### Monthly Revenue Share Inngest Function\n\n```typescript\n// inngest/functions/monthly-revenue-share.ts\nexport const monthlyRevenueShare = inngest.createFunction(\n  { id: 'monthly-revenue-share' },\n  { cron: '0 0 1 * *' }, // 1st of month\n  async ({ step }) =\u003e {\n    const period = await step.run('get-period', () =\u003e {\n      const now = new Date()\n      return {\n        start: startOfMonth(subMonths(now, 1)),\n        end: endOfMonth(subMonths(now, 1)),\n      }\n    })\n\n    // 1. Get total revenue for period\n    const totalRevenue = await step.run('get-revenue', () =\u003e\n      db.select({ amount: sum(transactions.amount) })\n        .from(transactions)\n        .where(and(\n          gte(transactions.createdAt, period.start),\n          lte(transactions.createdAt, period.end),\n          eq(transactions.pool, true) // Only poolable revenue\n        ))\n    )\n\n    // 2. Get lesson views with instructor attribution\n    const viewsByInstructor = await step.run('get-views', () =\u003e\n      db.select({\n        lessonId: lessonProgress.lessonId,\n        instructorId: contentContributions.userId,\n        percentageSplit: sql`JSON_EXTRACT(${contentContributions.metadata}, '$.percentageSplit')`,\n        viewCount: count(),\n      })\n      .from(lessonProgress)\n      .innerJoin(contentContributions, \n        eq(lessonProgress.lessonId, contentContributions.contentId))\n      .innerJoin(contributionTypes,\n        eq(contentContributions.contributionTypeId, contributionTypes.id))\n      .where(and(\n        gte(lessonProgress.completedAt, period.start),\n        lte(lessonProgress.completedAt, period.end),\n        eq(contributionTypes.slug, 'instructor'),\n        eq(contentContributions.active, true),\n      ))\n      .groupBy(lessonProgress.lessonId, contentContributions.userId)\n    )\n\n    // 3. Calculate totals and per-instructor amounts\n    const totalViews = viewsByInstructor.reduce((sum, v) =\u003e sum + v.viewCount, 0)\n    const valuePerView = totalRevenue / totalViews\n\n    // 4. Group by instructor and calculate payouts\n    const payouts = await step.run('calculate-payouts', () =\u003e {\n      const byInstructor = new Map()\n      \n      for (const view of viewsByInstructor) {\n        const current = byInstructor.get(view.instructorId) || { \n          segments: 0, \n          breakdown: {} \n        }\n        const split = view.percentageSplit || 0.5 // default 50%\n        const segments = view.viewCount * split\n        \n        current.segments += segments\n        current.breakdown[view.lessonId] = segments\n        byInstructor.set(view.instructorId, current)\n      }\n      \n      return Array.from(byInstructor.entries()).map(([instructorId, data]) =\u003e ({\n        userId: instructorId,\n        userSegments: data.segments,\n        amount: data.segments * valuePerView,\n        lessonBreakdown: data.breakdown,\n      }))\n    })\n\n    // 5. Insert revenue split records\n    await step.run('insert-splits', () =\u003e\n      db.insert(contributorRevenueSplits).values(\n        payouts.map(p =\u003e ({\n          id: createId(),\n          userId: p.userId,\n          periodStart: period.start,\n          periodEnd: period.end,\n          totalRevenue,\n          totalSegments: totalViews,\n          userSegments: p.userSegments,\n          percentageSplit: p.userSegments / totalViews,\n          amount: p.amount,\n          status: p.amount \u003e= 100 ? 'pending' : 'held', // Min payout threshold\n          metadata: { lessonBreakdown: p.lessonBreakdown },\n        }))\n      )\n    )\n\n    // 6. Send notification emails\n    await step.run('send-emails', async () =\u003e {\n      for (const payout of payouts.filter(p =\u003e p.amount \u003e= 20)) {\n        await inngest.send({\n          name: 'email/instructor-monthly-report',\n          data: { userId: payout.userId, periodStart: period.start },\n        })\n      }\n    })\n\n    return { processed: payouts.length, totalPaid: payouts.reduce((s, p) =\u003e s + p.amount, 0) }\n  }\n)\n```\n\n### Migration Path\n\n1. **Add ContributorRevenueSplit table** to CB schema\n2. **Populate ContentContribution** for all egghead instructors\n   - Map Rails `Instructor` â†’ CB `User`\n   - Map Rails `Lesson.instructor_id` â†’ `ContentContribution`\n   - Set `metadata.percentageSplit` from `InstructorRevenueSplit`\n3. **Add ContributionTypes**: 'instructor', 'co-instructor', 'mentor'\n4. **Build Inngest function** (above)\n5. **Backfill historical splits** (optional, for reporting continuity)\n\n### What We're NOT Porting\n\n- âŒ Plutus double-entry accounting\n- âŒ Per-series liability accounts\n- âŒ Rollup entries\n- âŒ Sellable-specific calculations (egghead doesn't use these)\n- âŒ Wildcard revenue splits (simplify to explicit contributions)\n\n### What We're Keeping\n\n- âœ… View-based revenue share (fair for subscription model)\n- âœ… Co-instructor splits\n- âœ… Minimum payout threshold ($100)\n- âœ… Monthly calculation cycle\n- âœ… Instructor email reports\n\n### Advances (Deferred)\n\nThe Rails system supports \"advances\" (pre-paying instructors against future earnings). This is complex and rarely used. **Defer to post-migration** - can add `advanceBalance` to User or separate table if needed.\n\n### Effort Estimate\n\n- Schema addition: 0.5 day\n- ContentContribution migration: 0.5 day  \n- Inngest function: 1 day\n- Testing with historical data: 1 day\n- **Total: 3 days**\n\n### Files Reference\n\n**Rails (for data migration):**\n- `app/models/instructor.rb` - instructor data\n- `app/models/instructor_revenue_split.rb` - percentage splits\n- `app/models/lesson.rb` - lesson â†’ instructor mapping\n\n**Coursebuilder (to modify):**\n- `packages/adapter-drizzle/src/lib/mysql/schemas/commerce/` - add ContributorRevenueSplit\n- `apps/egghead/src/inngest/` - add monthly-revenue-share function","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-11T10:26:36.456359-08:00","updated_at":"2025-12-11T10:32:36.717643-08:00","closed_at":"2025-12-11T10:32:36.717643-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.7","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T10:26:36.456742-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.8","title":"Audit cron workers - which are truly essential?","description":"## Audit Complete\n\n### All 17 Rails Cron Jobs Analyzed\n\n| Job | Schedule | Verdict | Reason |\n|-----|----------|---------|--------|\n| **StripeReconciler** | Daily 11pm | **PORT** | Catches missed webhooks - critical |\n| **GiftExpirationWorker** | Daily | **PORT** | Gift subscriptions must expire |\n| **MonthlyReportWorker** | 1st of month | **PORT** | Revenue share - see tkd.7 |\n| **LessonPublishWorker** | Every 10min | **SKIP** | CB doesn't have scheduled publishing yet, can add later |\n| **RefreshSitemap** | Every 4h | **SKIP** | CB uses Next.js native sitemap.ts - generates on-demand |\n| **SignInTokenCleaner** | Every minute | **SKIP** | CB handles via session expiry, tokens have TTL |\n| **PlaylistRanker** | 2x daily | **DEFER** | Nice-to-have, can rebuild ranking logic later |\n| **TagRanker** | Daily | **DEFER** | Nice-to-have, can rebuild later |\n| **AccountSubscriptionRenewalWorker** | Daily | **PORT** | Renewal reminder emails - good UX |\n| **DailyReportWorker** | Daily | **SKIP** | Admin convenience only |\n| **WeeklyReportWorker** | Weekly | **SKIP** | Empty/dead code |\n| **DailyMemberPromptEmailWorker** | Daily | **SKIP** | Marketing email, can add later |\n| **SamlProviderExpiration** | Daily | **DEFER** | Only ~15 enterprise accounts |\n| **RunHourlySummaryTables** | Hourly | **SKIP** | Analytics aggregation, rebuild if needed |\n| **SyncPodcastsWorker** | Every 10min | **SKIP** | Low priority |\n| **SellablePurchasesDigestWorker** | Daily | **SKIP** | Admin digest |\n| **CleanUnusedParityCoupons** | Daily | **SKIP** | Cleanup, can add later |\n\n### Essential Jobs to Port (4)\n1. **StripeReconciler** - Already in tkd.1\n2. **GiftExpirationWorker** - Already in tkd.2\n3. **MonthlyReportWorker** - Covered by tkd.7\n4. **AccountSubscriptionRenewalWorker** - NEW - add subtask\n\n### Summary\n- **PORT NOW:** 4 jobs\n- **DEFER:** 3 jobs (rankers, SAML)\n- **SKIP:** 10 jobs (handled by CB, dead code, or low priority)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T10:26:41.475033-08:00","updated_at":"2025-12-11T10:32:39.7545-08:00","closed_at":"2025-12-11T10:32:39.7545-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.8","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T10:26:41.475417-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-tkd.9","title":"Add ContributorRevenueSplit schema to Coursebuilder","description":"Add new table to track monthly instructor payouts.\n\n**Location:** `packages/adapter-drizzle/src/lib/mysql/schemas/commerce/contributor-revenue-split.ts`\n\n**Schema:** See migrate-egghead-tkd.7 description for full schema definition.\n\n**Key fields:**\n- userId, periodStart, periodEnd\n- totalRevenue, totalSegments, userSegments\n- percentageSplit, amount\n- status (pending/paid/held)\n- metadata (lessonBreakdown, calculationVersion)\n\n**Also add:**\n- Relations to User\n- Export from index\n- Migration file","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-11T10:32:42.768009-08:00","updated_at":"2025-12-11T10:32:42.768009-08:00","dependencies":[{"issue_id":"migrate-egghead-tkd.9","depends_on_id":"migrate-egghead-tkd","type":"parent-child","created_at":"2025-12-11T10:32:42.768407-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-u6b","title":"UI Migration Exploration: egghead-next â†’ Coursebuilder","description":"Research and document UI feature mapping from egghead-next to course-builder/apps/egghead. Analyze: user/account management, subscriptions, search, content gating, lessons, posts, courses.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-11T08:43:03.422922-08:00","updated_at":"2025-12-11T08:47:54.790181-08:00","closed_at":"2025-12-11T08:47:54.790181-08:00"}
{"id":"migrate-egghead-u6b.1","title":"Analyze egghead-next: User \u0026 Account Management","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T08:43:03.461063-08:00","updated_at":"2025-12-11T08:46:24.663845-08:00","closed_at":"2025-12-11T08:46:24.663845-08:00","dependencies":[{"issue_id":"migrate-egghead-u6b.1","depends_on_id":"migrate-egghead-u6b","type":"parent-child","created_at":"2025-12-11T08:43:03.461422-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-u6b.2","title":"Analyze egghead-next: Subscription \u0026 Payment UI","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T08:43:03.504616-08:00","updated_at":"2025-12-11T08:46:25.464998-08:00","closed_at":"2025-12-11T08:46:25.464998-08:00","dependencies":[{"issue_id":"migrate-egghead-u6b.2","depends_on_id":"migrate-egghead-u6b","type":"parent-child","created_at":"2025-12-11T08:43:03.504977-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-u6b.3","title":"Analyze egghead-next: Search Implementation","description":"Analyzed egghead-next search implementation - Typesense-powered InstantSearch with comprehensive filtering and curated landing pages","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T08:43:03.538367-08:00","updated_at":"2025-12-11T08:46:26.242576-08:00","closed_at":"2025-12-11T08:46:26.242576-08:00","dependencies":[{"issue_id":"migrate-egghead-u6b.3","depends_on_id":"migrate-egghead-u6b","type":"parent-child","created_at":"2025-12-11T08:43:03.538733-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-u6b.4","title":"Analyze egghead-next: Content Types (lessons, posts, courses)","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T08:43:03.571718-08:00","updated_at":"2025-12-11T08:46:27.183109-08:00","closed_at":"2025-12-11T08:46:27.183109-08:00","dependencies":[{"issue_id":"migrate-egghead-u6b.4","depends_on_id":"migrate-egghead-u6b","type":"parent-child","created_at":"2025-12-11T08:43:03.572035-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-u6b.5","title":"Analyze Coursebuilder: Existing egghead app features","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T08:43:03.605111-08:00","updated_at":"2025-12-11T08:46:28.225209-08:00","closed_at":"2025-12-11T08:46:28.225209-08:00","dependencies":[{"issue_id":"migrate-egghead-u6b.5","depends_on_id":"migrate-egghead-u6b","type":"parent-child","created_at":"2025-12-11T08:43:03.605444-08:00","created_by":"daemon"}]}
{"id":"migrate-egghead-u6b.6","title":"Synthesize: Gap analysis and migration roadmap","description":"","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-11T08:43:03.640611-08:00","updated_at":"2025-12-11T08:47:53.296487-08:00","closed_at":"2025-12-11T08:47:53.296487-08:00","dependencies":[{"issue_id":"migrate-egghead-u6b.6","depends_on_id":"migrate-egghead-u6b","type":"parent-child","created_at":"2025-12-11T08:43:03.640955-08:00","created_by":"daemon"}]}
